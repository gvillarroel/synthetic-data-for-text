{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install optuna pytorch_lightning rouge-score transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22059, 17)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>property_type</th>\n",
       "      <th>transaction_type</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>rooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>m_built</th>\n",
       "      <th>m_size</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>address</th>\n",
       "      <th>owner</th>\n",
       "      <th>_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>615870</th>\n",
       "      <td>https://www.economicos.cl/propiedades/departam...</td>\n",
       "      <td>Amplio departamento amoblado. Un dormitorio, l...</td>\n",
       "      <td>$ 350.000</td>\n",
       "      <td>Departamento</td>\n",
       "      <td>Arriendo</td>\n",
       "      <td>Metropolitana de Santiago</td>\n",
       "      <td>Providencia</td>\n",
       "      <td>2019-12-03 00:04:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>El Mercurio</td>\n",
       "      <td>Departamento en Arriendo en Providencia 1 dorm...</td>\n",
       "      <td>Providencia, Metropolitana de Santiago</td>\n",
       "      <td></td>\n",
       "      <td>12.391648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447327</th>\n",
       "      <td>https://www.economicos.cl/propiedades/departam...</td>\n",
       "      <td>Departamento, cuenta con living comedor, logia...</td>\n",
       "      <td>$ 146.100.000</td>\n",
       "      <td>Departamento</td>\n",
       "      <td>Venta</td>\n",
       "      <td>Metropolitana de Santiago</td>\n",
       "      <td>Ñuñoa</td>\n",
       "      <td>2019-06-14 00:04:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>El Mercurio</td>\n",
       "      <td>Departamento en Venta en Ñuñoa 3 dormitorios 2...</td>\n",
       "      <td>Ñuñoa, Metropolitana de Santiago</td>\n",
       "      <td>Blanchet propiedades</td>\n",
       "      <td>5252.671111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589765</th>\n",
       "      <td>https://www.economicos.cl/propiedades/casa-en-...</td>\n",
       "      <td>FY9018\\n\\nAmplia casa con inmejorable ubicacio...</td>\n",
       "      <td>29.800 UF</td>\n",
       "      <td>Casa</td>\n",
       "      <td>Venta</td>\n",
       "      <td>Metropolitana de Santiago</td>\n",
       "      <td>Vitacura</td>\n",
       "      <td>2022-02-23 00:00:29</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>627.0</td>\n",
       "      <td>El Mercurio</td>\n",
       "      <td>Casa en Venta en Vitacura 7 dormitorios 4 baños</td>\n",
       "      <td>Gerónimo de Alderete Vitacura, Metropolitana d...</td>\n",
       "      <td>Property Partners Chile S.A</td>\n",
       "      <td>29800.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      url  \\\n",
       "615870  https://www.economicos.cl/propiedades/departam...   \n",
       "447327  https://www.economicos.cl/propiedades/departam...   \n",
       "589765  https://www.economicos.cl/propiedades/casa-en-...   \n",
       "\n",
       "                                              description          price  \\\n",
       "615870  Amplio departamento amoblado. Un dormitorio, l...      $ 350.000   \n",
       "447327  Departamento, cuenta con living comedor, logia...  $ 146.100.000   \n",
       "589765  FY9018\\n\\nAmplia casa con inmejorable ubicacio...      29.800 UF   \n",
       "\n",
       "       property_type transaction_type                      state       county  \\\n",
       "615870  Departamento         Arriendo  Metropolitana de Santiago  Providencia   \n",
       "447327  Departamento            Venta  Metropolitana de Santiago        Ñuñoa   \n",
       "589765          Casa            Venta  Metropolitana de Santiago     Vitacura   \n",
       "\n",
       "          publication_date  rooms  bathrooms  m_built  m_size       source  \\\n",
       "615870 2019-12-03 00:04:00    1.0        1.0     35.0    35.0  El Mercurio   \n",
       "447327 2019-06-14 00:04:00    3.0        2.0     75.0    75.0  El Mercurio   \n",
       "589765 2022-02-23 00:00:29    7.0        4.0    200.0   627.0  El Mercurio   \n",
       "\n",
       "                                                    title  \\\n",
       "615870  Departamento en Arriendo en Providencia 1 dorm...   \n",
       "447327  Departamento en Venta en Ñuñoa 3 dormitorios 2...   \n",
       "589765    Casa en Venta en Vitacura 7 dormitorios 4 baños   \n",
       "\n",
       "                                                  address  \\\n",
       "615870             Providencia, Metropolitana de Santiago   \n",
       "447327                   Ñuñoa, Metropolitana de Santiago   \n",
       "589765  Gerónimo de Alderete Vitacura, Metropolitana d...   \n",
       "\n",
       "                               owner        _price  \n",
       "615870                                   12.391648  \n",
       "447327          Blanchet propiedades   5252.671111  \n",
       "589765   Property Partners Chile S.A  29800.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#.replace(to_replace=\"-1\", value=np.nan)\n",
    "df = pd.read_parquet('../datasets/economicos/synth/split/train.parquet').replace(to_replace=\"None\", value=np.nan).replace(to_replace=-1, value=np.nan)\n",
    "display(df.shape)\n",
    "CHAR_SEP = \" \"\n",
    "df.sample(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['description this data:', '2022-07-21 precio 3.990 UF tipo Casa transacción Venta región Valparaíso comuna Quilpué dormitorios 3.0 baños 3.0 constuidos 88.0 terreno 280.0 precio_real 3990.0 titulo: Casa en Venta en Quilpué 3 dormitorios 2 baños dirección: Centro de Quilpué Quilpué, Valparaíso'], 'target': 'Venta Casa Independiente   Céntrica en Quilpué  Casa independiente, de un piso, construcción sólida, sector residencial, excelente ubicación, a solo seis cuadras del centro de Quilpué, gran conectividad, locomoción a la puerta a Viña del mar, Valparaíso, Villa Alemana y Local, cercana a Colegios, Supermercado y Comercio en general.  La propiedad cuenta con amplio living comedor con piso flotante, 3 habitaciones (2 amplias y una pequeña), 2 baños completos (uno con receptáculo y otro con tina), cocina con espacio para despensa.  CARACTERÍSTICAS:  Habitaciones: 3  Baños: 2  Estacionamiento: 3  Superficie Total: 280 m2  Superficie Construida: 88 m2  VALOR: + 2% COMISIÓN'}\n",
      "{'text': ['title this data:', '2022-02-23 precio 7.590 UF tipo Departamento transacción Venta región Metropolitana de Santiago comuna Las Condes dormitorios 2.0 baños 2.0 constuidos 76.0 terreno 85.0 precio_real 7590.0 titulo: Departamento en Venta en Las Condes 2 dormitorios 2 baños dirección: Bello Horizonte / Martín de Zamora Las Condes, Metropolitana de Santiago'], 'target': 'Departamento en Venta en Las Condes 2 dormitorios 2 baños'}\n",
      "{'text': ['address this data:', '2019-05-30 precio $ 89.000.000 tipo Casa transacción Venta región Metropolitana de Santiago comuna Cerrillos dormitorios 3.0 baños 3.0 constuidos 63.0 terreno 166.0 precio_real 3206.068114312989 titulo: Vendo Casa Modelo Napoles Villa Plaza Oeste  dirección: Carriel Sur 3172, Comuna de Cerrillos, Santiago Región Metropolitana  Cerrillos, Metropolitana de Santiago'], 'target': 'Carriel Sur 3172, Comuna de Cerrillos, Santiago Región Metropolitana  Cerrillos, Metropolitana de Santiago'}\n"
     ]
    }
   ],
   "source": [
    "def convert(row, column=\"description\"):\n",
    "    return {\n",
    "        \"text\": [f\"{column} this data:\", f\"\"\"{row.publication_date.strftime('%Y-%m-%d')}\n",
    "precio {row.price}\n",
    "tipo {row.property_type}\n",
    "transacción {row.transaction_type}\n",
    "región {row.state}\n",
    "comuna {row.county}\n",
    "dormitorios {row.rooms}\n",
    "baños {row.rooms}\n",
    "constuidos {row.m_built}\n",
    "terreno {row.m_size}\n",
    "precio_real {row._price}\n",
    "titulo: {row.title}\n",
    "dirección: {row.address}\"\"\".replace(\"\\n\", \" \")],\n",
    "        \"target\": row[column]\n",
    "        }\n",
    "\n",
    "from functools import partial\n",
    "print(\n",
    "    df.sample(1).apply(convert, axis=1).iloc[-1]\n",
    ")\n",
    "print(\n",
    "    df.sample(1).apply(partial(convert, column=\"title\"), axis=1).iloc[-1]\n",
    ")\n",
    "print(\n",
    "    df.sample(1).apply(partial(convert, column=\"address\"), axis=1).iloc[-1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7974</th>\n",
       "      <td>[address this data:, 2022-02-27 precio 2.570 U...</td>\n",
       "      <td>Depto san miguel en pedro Alarcón 2d-1b San Mi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "7974  [address this data:, 2022-02-27 precio 2.570 U...   \n",
       "\n",
       "                                                 target  \n",
       "7974  Depto san miguel en pedro Alarcón 2d-1b San Mi...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text = pd.concat([pd.DataFrame(df.apply(convert, axis=1).to_list()), pd.DataFrame(df.apply(partial(convert, column=\"title\"), axis=1).to_list()), pd.DataFrame(df.apply(partial(convert, column=\"address\"), axis=1).to_list())])\n",
    "df_text.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from argparse import ArgumentParser\n",
    "from os.path import join, isfile\n",
    "from os import listdir\n",
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from rouge_score import rouge_scorer\n",
    "import shutil\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import  DataLoader, RandomSampler, SequentialSampler #Dataset,\n",
    "from transformers import get_linear_schedule_with_warmup, AdamW\n",
    "# Importing the T5 modules from huggingface/transformers\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "def set_seed(seed):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCallback(pl.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.metrics = []\n",
    "\n",
    "    def on_validation_end(self, trainer, pl_module):\n",
    "        self.metrics.append(trainer.callback_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAR_SEP = \" \"\n",
    "MAX_SRC_LEN = 150\n",
    "MAX_TGT_LEN = 720\n",
    "from torchmetrics.text.bert import BERTScore\n",
    "\n",
    "class T5Finetuner(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, args, df, batch_size=1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.args = args\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(self.args.model)\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(self.args.model)\n",
    "        self.data = df\n",
    "        #self.scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "        self.scorer = BERTScore()\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def _encode_text(self, text_input, target):\n",
    "      ctext = str(text_input)\n",
    "      ctext = CHAR_SEP.join(ctext.split())\n",
    "      target = str(target) #summarized text\n",
    "      target = CHAR_SEP.join(target.split())\n",
    "      source = self.tokenizer.batch_encode_plus([ctext], \n",
    "                                                max_length= MAX_SRC_LEN, \n",
    "                                                truncation=True,\n",
    "                                                padding='max_length',\n",
    "                                                return_tensors='pt')\n",
    "      target = self.tokenizer.batch_encode_plus([target], \n",
    "                                                max_length=MAX_TGT_LEN,\n",
    "                                                truncation=True,\n",
    "                                                padding='max_length',\n",
    "                                                return_tensors='pt')\n",
    "      y = target['input_ids']\n",
    "      target_id = y[:, :-1].contiguous()\n",
    "      target_label = y[:, 1:].clone().detach()\n",
    "      target_label[y[:, 1:] == self.tokenizer.pad_token_id] = -100 #in case the labels are not provided, empty string\n",
    "      return source['input_ids'], source['attention_mask'], target_id, target_label\n",
    "    \n",
    "    def encode_text(self, text, target):\n",
    "        source = self.tokenizer.batch_encode_plus([text], \n",
    "                                                max_length= MAX_SRC_LEN, \n",
    "                                                truncation=True,\n",
    "                                                padding='max_length',\n",
    "                                                return_tensors='pt')\n",
    "        target = self.tokenizer.batch_encode_plus([target], \n",
    "                                                max_length=MAX_TGT_LEN,\n",
    "                                                truncation=True,\n",
    "                                                padding='max_length',\n",
    "                                                return_tensors='pt')\n",
    "        y = target['input_ids']\n",
    "        target_id = y[:, :-1].contiguous()\n",
    "        target_label = y[:, 1:].clone().detach()\n",
    "        target_label[y[:, 1:] == self.tokenizer.pad_token_id] = -100 #in case the labels are not provided, empty string\n",
    "        return source['input_ids'], source['attention_mask'], target_id, target_label\n",
    "\n",
    "        \n",
    "    \n",
    "    def prepare_data(self):\n",
    "        source_ids, source_masks, target_ids, target_labels = [], [], [], [] \n",
    "        for _, row in self.data.iterrows():\n",
    "            source_id, source_mask, target_id, target_label = self.encode_text(row.text, row.target)\n",
    "            source_ids.append(source_id)\n",
    "            source_masks.append(source_mask)\n",
    "            target_ids.append(target_id)\n",
    "            target_labels.append(target_label)\n",
    "\n",
    "        # Convert the lists into tensors\n",
    "        source_ids = torch.cat(source_ids, dim=0)\n",
    "        source_masks = torch.cat(source_masks, dim=0)\n",
    "        target_ids = torch.cat(target_ids, dim=0)\n",
    "        target_labels = torch.cat(target_labels, dim=0)\n",
    "        # splitting the data to train, validation, and test\n",
    "        data = TensorDataset(source_ids, source_masks, target_ids, target_labels)\n",
    "        train_size, val_size = int(0.8 * len(data)), int(0.1 * len(data))\n",
    "        test_size = len(data) - (train_size + val_size)\n",
    "        self.train_dat, self.val_dat, self.test_dat = \\\n",
    "            random_split(data, [train_size, val_size, test_size])\n",
    "    \n",
    "    def forward(self, batch, batch_idx):\n",
    "        source_ids, source_mask, target_ids, target_labels = batch[:4]\n",
    "        return self.model(input_ids = source_ids, attention_mask = source_mask, \n",
    "                          decoder_input_ids=target_ids, labels=target_labels)\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self(batch, batch_idx)[0]\n",
    "        return {'loss': loss, 'log': {'train_loss': loss}}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self(batch, batch_idx)[0]\n",
    "        return {'loss': loss, 'val_loss': loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        loss = sum([o['loss'] for o in outputs]) / len(outputs)\n",
    "        out = {'val_loss': loss}\n",
    "        return {**out, 'log': out}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss = self(batch, batch_idx)[0]\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        loss = sum([o['loss'] for o in outputs]) / len(outputs)\n",
    "        out = {'test_loss': loss}\n",
    "        return {**out, 'log': out}\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dat, batch_size=self.batch_size,\n",
    "                          num_workers=4, sampler=RandomSampler(self.train_dat))\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dat, batch_size=self.args.bs, num_workers=4,\n",
    "                          sampler=SequentialSampler(self.val_dat))\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dat, batch_size=self.args.bs, num_workers=4,\n",
    "                          sampler=SequentialSampler(self.test_dat))    \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.model.parameters(), lr=self.args.lr, eps=1e-4)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps=0,\n",
    "            num_training_steps=self.args.max_epochs * len(self.train_dat))\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}\n",
    "    \n",
    "    def generate_summary(self, ctext, summ_len=150, text='', beam_search=2, repetition_penalty=2.5):\n",
    "        source_id, source_mask, target_id, target_label = self.encode_text(ctext, text)\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            generated_ids = self.model.generate(\n",
    "                input_ids = source_id,\n",
    "                attention_mask = source_mask, \n",
    "                max_length=summ_len, \n",
    "                truncation=True,\n",
    "                num_beams=beam_search,\n",
    "                repetition_penalty=repetition_penalty, \n",
    "                length_penalty=1.0, \n",
    "                early_stopping=True\n",
    "                )\n",
    "            prediction = [self.tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "        if len(text) > 0:\n",
    "            target = [self.tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in target_id]\n",
    "            scores = self.scorer.score(target[0], prediction[0])\n",
    "            return prediction, scores\n",
    "        else:\n",
    "            return prediction\n",
    "        \n",
    "\n",
    "    def save_core_model(self):\n",
    "        store_path = join(self.args.output, self.args.name, 'core')\n",
    "        self.model.save_pretrained(store_path)\n",
    "        self.tokenizer.save_pretrained(store_path)\n",
    "        \n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser):\n",
    "        p = ArgumentParser(parents=[parent_parser], add_help=False)\n",
    "        p.add_argument('-m', '--model', type=str, default='t5-base',\n",
    "                       help='name of the model or the path pointing to it')\n",
    "        p.add_argument('--bs', '--batch_size', type=int, default=2)\n",
    "        p.add_argument('--source_len', type=int, default=120)\n",
    "        p.add_argument('--summ_len', type=int, default=700)\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_args():\n",
    "    p = ArgumentParser()\n",
    "    p.add_argument('-p', '--path', type=str,  \n",
    "                   default='/content/gdrive/My Drive/Colab Notebooks/data/text_summarization_t5/news_summary.csv',\n",
    "                  help='path to the data file')\n",
    "    p.add_argument('-o', '--output', type=str, default='/tmp/tpu-template',\n",
    "                  help='path to the output directory for storing the model')\n",
    "    p.add_argument('-n', '--name', type=str, default='google/t5-v1_1-xxl',\n",
    "                  help='this name will be used on tensorboard for the model')\n",
    "    p.add_argument('-t', '--trials', type=int, default=1,\n",
    "                  help='number of trials for hyperparameter search')\n",
    "    p.add_argument('--seed', type=int, default=0, help='randomization seed')\n",
    "    p = T5Finetuner.add_model_specific_args(p)\n",
    "    p = pl.Trainer.add_argparse_args(p)\n",
    "    args,_ = p.parse_known_args()\n",
    "    args.max_epochs = 2\n",
    "    return args\n",
    "\n",
    "def default_args():\n",
    "    p = ArgumentParser()\n",
    "    args,_ = p.parse_known_args()\n",
    "    args.max_epochs = 2\n",
    "    #args.model = \"google/flan-t5-small\"\n",
    "    #args.model = \"google/flan-t5-xl\"\n",
    "    args.model = \"google/mt5-large\"\n",
    "    #args.model = \"google/flan-t5-large\"\n",
    "    #args.model = \"google/flan-t5-base\"\n",
    "    args.output = f\"./{args.model.replace('/','_')}_2\"\n",
    "    args.name = \"DESCRIPCION_PROPIEDADES\"\n",
    "    args.bs = 1 # batch size\n",
    "    return args\n",
    "\n",
    "def optuna_objective(trial):\n",
    "    args = default_args()\n",
    "    # sampling the hyperparameters\n",
    "    args.lr = trial.suggest_categorical(\"lr\", [5e-4])\n",
    "    # setting up the right callbacks\n",
    "    cp_callback = pl.callbacks.ModelCheckpoint(\n",
    "        join(args.output, args.name, f\"trial_{trial.number}\", \"{epoch}\"),\n",
    "        monitor=\"val_loss\", mode=\"min\")\n",
    "    pr_callback = PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")\n",
    "    metrics_callback = MetricsCallback()\n",
    "    summarizer = T5Finetuner(args, df_text)         # loading the model\n",
    "    trainer = pl.Trainer.from_argparse_args(      # loading the trainer\n",
    "        args, \n",
    "        accelerator=\"gpu\",\n",
    "        devices=1,\n",
    "        precision=16,\n",
    "        default_root_dir=args.output, gradient_clip_val=1.0,\n",
    "        #checkpoint_callback=cp_callback,\n",
    "        callbacks=[metrics_callback],\n",
    "        #early_stop_callback=pr_callback, \n",
    "        num_sanity_val_steps=-1,\n",
    "        #auto_scale_batch_size=\"power\",\n",
    "        # select TensorBoad or Wandb logger\n",
    "        logger=TensorBoardLogger(join(args.output, 'logs'), name=args.name, version=f'trial_{trial.number}')\n",
    "        )\n",
    "    trainer.fit(summarizer)                       # fitting the model\n",
    "    #trainer.test(summarizer)                      # testing the model\n",
    "    return min([x['val_loss'].item() for x in metrics_callback.metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-16 14:57:26,072]\u001b[0m A new study created in memory with name: no-name-a3419d29-d960-47d2-81bb-4af99f76859f\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf07dca89164492ca7baf3158cad79e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type mt5 to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92490776d6ab4447a3554a1e358484a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce880216f1b44f08e13f8ffcc5aee40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329080e0b5c643a19c27532ea086f2f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e15e90c9f714c82bc706c3a2ccb3163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/376 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/torchmetrics/text/bert.py:163: UserWarning: The argument `model_name_or_path` was not specified while it is required when the default `transformers` model is used. It will use the default recommended model - 'roberta-large'.\n",
      "  warn(\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name   | Type                       | Params\n",
      "------------------------------------------------------\n",
      "0 | model  | T5ForConditionalGeneration | 1.2 B \n",
      "1 | scorer | BERTScore                  | 0     \n",
      "------------------------------------------------------\n",
      "1.2 B     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 B     Total params\n",
      "2,459.163 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c827a75220466681e963a4db5a5b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e1ac878bb846c1a5b26c2c34544ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2023-01-16 15:06:15,085]\u001b[0m Trial 0 failed because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 23.63 GiB total capacity; 20.63 GiB already allocated; 54.50 MiB free; 20.73 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_38403/1038177041.py\", line 58, in optuna_objective\n",
      "    trainer.fit(summarizer)                       # fitting the model\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 603, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 38, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 645, in _fit_impl\n",
      "    self._run(model, ckpt_path=self.ckpt_path)\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1098, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1177, in _run_stage\n",
      "    self._run_train()\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1200, in _run_train\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 267, in advance\n",
      "    self._outputs = self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 214, in advance\n",
      "    batch_output = self.batch_loop.run(kwargs)\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 88, in advance\n",
      "    outputs = self.optimizer_loop.run(optimizers, kwargs)\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 200, in advance\n",
      "    result = self._run_optimization(kwargs, self._optimizers[self.optim_progress.optimizer_position])\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 247, in _run_optimization\n",
      "    self._optimizer_step(optimizer, opt_idx, kwargs.get(\"batch_idx\", 0), closure)\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 357, in _optimizer_step\n",
      "    self.trainer._call_lightning_module_hook(\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1342, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/core/module.py\", line 1661, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py\", line 169, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 234, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/native_amp.py\", line 85, in optimizer_step\n",
      "    closure_result = closure()\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 147, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 133, in closure\n",
      "    step_output = self._step_fn()\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 406, in _training_step\n",
      "    training_step_output = self.trainer._call_strategy_hook(\"training_step\", *kwargs.values())\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1480, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 378, in training_step\n",
      "    return self.model.training_step(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_38403/2439732350.py\", line 86, in training_step\n",
      "    loss = self(batch, batch_idx)[0]\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/tmp/ipykernel_38403/2439732350.py\", line 82, in forward\n",
      "    return self.model(input_ids = source_ids, attention_mask = source_mask,\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\", line 1648, in forward\n",
      "    decoder_outputs = self.decoder(\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\", line 1040, in forward\n",
      "    layer_outputs = layer_module(\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\", line 673, in forward\n",
      "    self_attention_outputs = self.layer[0](\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\", line 579, in forward\n",
      "    attention_output = self.SelfAttention(\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\", line 509, in forward\n",
      "    scores = torch.matmul(\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 23.63 GiB total capacity; 20.63 GiB already allocated; 54.50 MiB free; 20.73 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 23.63 GiB total capacity; 20.63 GiB already allocated; 54.50 MiB free; 20.73 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study()\n\u001b[0;32m----> 2\u001b[0m study\u001b[39m.\u001b[39;49moptimize(optuna_objective, show_progress_bar\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/optuna/study/study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    316\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    325\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \n\u001b[1;32m    328\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m     _optimize(\n\u001b[1;32m    420\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    421\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    422\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    423\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    424\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    425\u001b[0m         catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[1;32m    426\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    427\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    428\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    429\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    161\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/optuna/study/_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    230\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    231\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    233\u001b[0m ):\n\u001b[0;32m--> 234\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    197\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn [9], line 58\u001b[0m, in \u001b[0;36moptuna_objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     43\u001b[0m summarizer \u001b[39m=\u001b[39m T5Finetuner(args, df_text)         \u001b[39m# loading the model\u001b[39;00m\n\u001b[1;32m     44\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer\u001b[39m.\u001b[39mfrom_argparse_args(      \u001b[39m# loading the trainer\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     args, \n\u001b[1;32m     46\u001b[0m     accelerator\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpu\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m     logger\u001b[39m=\u001b[39mTensorBoardLogger(join(args\u001b[39m.\u001b[39moutput, \u001b[39m'\u001b[39m\u001b[39mlogs\u001b[39m\u001b[39m'\u001b[39m), name\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mname, version\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrial_\u001b[39m\u001b[39m{\u001b[39;00mtrial\u001b[39m.\u001b[39mnumber\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     57\u001b[0m     )\n\u001b[0;32m---> 58\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(summarizer)                       \u001b[39m# fitting the model\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39m#trainer.test(summarizer)                      # testing the model\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mmin\u001b[39m([x[\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mitem() \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m metrics_callback\u001b[39m.\u001b[39mmetrics])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:603\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`Trainer.fit()` requires a `LightningModule`, got: \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    602\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 603\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    604\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    605\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     37\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     41\u001b[0m     trainer\u001b[39m.\u001b[39m_call_teardown_hook()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:645\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    638\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    639\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_set_ckpt_path(\n\u001b[1;32m    640\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    641\u001b[0m     ckpt_path,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    642\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    643\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    644\u001b[0m )\n\u001b[0;32m--> 645\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    647\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    648\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1098\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mrestore_training_state()\n\u001b[1;32m   1096\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mresume_end()\n\u001b[0;32m-> 1098\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m   1100\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1101\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_teardown()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1177\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[1;32m   1176\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_predict()\n\u001b[0;32m-> 1177\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_train()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1200\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_loop\u001b[39m.\u001b[39mtrainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n\u001b[1;32m   1199\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1200\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_loop\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:267\u001b[0m, in \u001b[0;36mFitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_fetcher\u001b[39m.\u001b[39msetup(dataloader, batch_to_device\u001b[39m=\u001b[39mbatch_to_device)\n\u001b[1;32m    266\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_epoch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 267\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:214\u001b[0m, in \u001b[0;36mTrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_started()\n\u001b[1;32m    213\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_batch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 214\u001b[0m         batch_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_loop\u001b[39m.\u001b[39;49mrun(kwargs)\n\u001b[1;32m    216\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n\u001b[1;32m    218\u001b[0m \u001b[39m# update non-plateau LR schedulers\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[39m# update epoch-interval ones only when we are at the end of training epoch\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py:88\u001b[0m, in \u001b[0;36mTrainingBatchLoop.advance\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mlightning_module\u001b[39m.\u001b[39mautomatic_optimization:\n\u001b[1;32m     85\u001b[0m     optimizers \u001b[39m=\u001b[39m _get_active_optimizers(\n\u001b[1;32m     86\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39moptimizers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39moptimizer_frequencies, kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mbatch_idx\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[1;32m     87\u001b[0m     )\n\u001b[0;32m---> 88\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer_loop\u001b[39m.\u001b[39;49mrun(optimizers, kwargs)\n\u001b[1;32m     89\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanual_loop\u001b[39m.\u001b[39mrun(kwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:200\u001b[0m, in \u001b[0;36mOptimizerLoop.advance\u001b[0;34m(self, optimizers, kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madvance\u001b[39m(\u001b[39mself\u001b[39m, optimizers: List[Tuple[\u001b[39mint\u001b[39m, Optimizer]], kwargs: OrderedDict) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_kwargs(kwargs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_idx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hiddens)\n\u001b[0;32m--> 200\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_optimization(kwargs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizers[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptim_progress\u001b[39m.\u001b[39;49moptimizer_position])\n\u001b[1;32m    201\u001b[0m     \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mloss \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# automatic optimization assumes a loss needs to be returned for extras to be considered as the batch\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         \u001b[39m# would be skipped otherwise\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_idx] \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39masdict()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:247\u001b[0m, in \u001b[0;36mOptimizerLoop._run_optimization\u001b[0;34m(self, kwargs, optimizer)\u001b[0m\n\u001b[1;32m    239\u001b[0m         closure()\n\u001b[1;32m    241\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[39m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[39m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    246\u001b[0m     \u001b[39m# the `batch_idx` is optional with inter-batch parallelism\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer_step(optimizer, opt_idx, kwargs\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mbatch_idx\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m0\u001b[39;49m), closure)\n\u001b[1;32m    249\u001b[0m result \u001b[39m=\u001b[39m closure\u001b[39m.\u001b[39mconsume_result()\n\u001b[1;32m    251\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mloss \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    252\u001b[0m     \u001b[39m# if no result, user decided to skip optimization\u001b[39;00m\n\u001b[1;32m    253\u001b[0m     \u001b[39m# otherwise update running loss + reset accumulated loss\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     \u001b[39m# TODO: find proper way to handle updating running loss\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:357\u001b[0m, in \u001b[0;36mOptimizerLoop._optimizer_step\u001b[0;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_progress\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep\u001b[39m.\u001b[39mincrement_ready()\n\u001b[1;32m    356\u001b[0m \u001b[39m# model hook\u001b[39;00m\n\u001b[0;32m--> 357\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_call_lightning_module_hook(\n\u001b[1;32m    358\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39moptimizer_step\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    359\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mcurrent_epoch,\n\u001b[1;32m    360\u001b[0m     batch_idx,\n\u001b[1;32m    361\u001b[0m     optimizer,\n\u001b[1;32m    362\u001b[0m     opt_idx,\n\u001b[1;32m    363\u001b[0m     train_step_and_backward_closure,\n\u001b[1;32m    364\u001b[0m     on_tpu\u001b[39m=\u001b[39;49m\u001b[39misinstance\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49maccelerator, TPUAccelerator),\n\u001b[1;32m    365\u001b[0m     using_native_amp\u001b[39m=\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mamp_backend \u001b[39m==\u001b[39;49m AMPType\u001b[39m.\u001b[39;49mNATIVE),\n\u001b[1;32m    366\u001b[0m     using_lbfgs\u001b[39m=\u001b[39;49mis_lbfgs,\n\u001b[1;32m    367\u001b[0m )\n\u001b[1;32m    369\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m should_accumulate:\n\u001b[1;32m    370\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_progress\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep\u001b[39m.\u001b[39mincrement_completed()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1342\u001b[0m, in \u001b[0;36mTrainer._call_lightning_module_hook\u001b[0;34m(self, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1339\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m hook_name\n\u001b[1;32m   1341\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[LightningModule]\u001b[39m\u001b[39m{\u001b[39;00mpl_module\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1342\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1344\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   1345\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/core/module.py:1661\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimizer_step\u001b[39m(\n\u001b[1;32m   1580\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1581\u001b[0m     epoch: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1588\u001b[0m     using_lbfgs: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1589\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1590\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1591\u001b[0m \u001b[39m    Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m \u001b[39m    each optimizer.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1659\u001b[0m \n\u001b[1;32m   1660\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1661\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep(closure\u001b[39m=\u001b[39;49moptimizer_closure)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py:169\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\u001b[39m\"\u001b[39m\u001b[39mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    168\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strategy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_strategy\u001b[39m.\u001b[39;49moptimizer_step(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer_idx, closure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    171\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_on_after_step()\n\u001b[1;32m    173\u001b[0m \u001b[39mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py:234\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, opt_idx, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39m# TODO(lite): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(model, pl\u001b[39m.\u001b[39mLightningModule)\n\u001b[0;32m--> 234\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprecision_plugin\u001b[39m.\u001b[39;49moptimizer_step(\n\u001b[1;32m    235\u001b[0m     optimizer, model\u001b[39m=\u001b[39;49mmodel, optimizer_idx\u001b[39m=\u001b[39;49mopt_idx, closure\u001b[39m=\u001b[39;49mclosure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    236\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/native_amp.py:85\u001b[0m, in \u001b[0;36mNativeMixedPrecisionPlugin.optimizer_step\u001b[0;34m(self, optimizer, model, optimizer_idx, closure, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(optimizer, LBFGS):\n\u001b[1;32m     82\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\n\u001b[1;32m     83\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNative AMP and the LBFGS optimizer are not compatible (optimizer \u001b[39m\u001b[39m{\u001b[39;00moptimizer_idx\u001b[39m}\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     84\u001b[0m     )\n\u001b[0;32m---> 85\u001b[0m closure_result \u001b[39m=\u001b[39m closure()\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _optimizer_handles_unscaling(optimizer):\n\u001b[1;32m     88\u001b[0m     \u001b[39m# Unscaling needs to be performed here in case we are going to apply gradient clipping.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m     \u001b[39m# Optimizers that perform unscaling in their `.step()` method are not supported (e.g., fused Adam).\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     \u001b[39m# Note: `unscale` happens after the closure is executed, but before the `on_before_optimizer_step` hook.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39munscale_(optimizer)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:147\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclosure(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    148\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\u001b[39m.\u001b[39mloss\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:133\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclosure\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ClosureResult:\n\u001b[0;32m--> 133\u001b[0m     step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step_fn()\n\u001b[1;32m    135\u001b[0m     \u001b[39mif\u001b[39;00m step_output\u001b[39m.\u001b[39mclosure_loss \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarning_cache\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:406\u001b[0m, in \u001b[0;36mOptimizerLoop._training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[39m\"\"\"Performs the actual train step with the tied hooks.\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \n\u001b[1;32m    399\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[39m    A ``ClosureResult`` containing the training step output.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[39m# manually capture logged metrics\u001b[39;00m\n\u001b[0;32m--> 406\u001b[0m training_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_call_strategy_hook(\u001b[39m\"\u001b[39;49m\u001b[39mtraining_step\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[1;32m    407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mpost_training_step()\n\u001b[1;32m    409\u001b[0m model_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39m_call_lightning_module_hook(\u001b[39m\"\u001b[39m\u001b[39mtraining_step_end\u001b[39m\u001b[39m\"\u001b[39m, training_step_output)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1480\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1480\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1482\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   1483\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py:378\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mtrain_step_context():\n\u001b[1;32m    377\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, TrainingStep)\n\u001b[0;32m--> 378\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mtraining_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "Cell \u001b[0;32mIn [8], line 86\u001b[0m, in \u001b[0;36mT5Finetuner.training_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtraining_step\u001b[39m(\u001b[39mself\u001b[39m, batch, batch_idx):\n\u001b[0;32m---> 86\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(batch, batch_idx)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     87\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m: loss, \u001b[39m'\u001b[39m\u001b[39mlog\u001b[39m\u001b[39m'\u001b[39m: {\u001b[39m'\u001b[39m\u001b[39mtrain_loss\u001b[39m\u001b[39m'\u001b[39m: loss}}\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [8], line 82\u001b[0m, in \u001b[0;36mT5Finetuner.forward\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, batch, batch_idx):\n\u001b[1;32m     81\u001b[0m     source_ids, source_mask, target_ids, target_labels \u001b[39m=\u001b[39m batch[:\u001b[39m4\u001b[39m]\n\u001b[0;32m---> 82\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(input_ids \u001b[39m=\u001b[39;49m source_ids, attention_mask \u001b[39m=\u001b[39;49m source_mask, \n\u001b[1;32m     83\u001b[0m                       decoder_input_ids\u001b[39m=\u001b[39;49mtarget_ids, labels\u001b[39m=\u001b[39;49mtarget_labels)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:1648\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         decoder_attention_mask \u001b[39m=\u001b[39m decoder_attention_mask\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mfirst_device)\n\u001b[1;32m   1647\u001b[0m \u001b[39m# Decode\u001b[39;00m\n\u001b[0;32m-> 1648\u001b[0m decoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\n\u001b[1;32m   1649\u001b[0m     input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[1;32m   1650\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[1;32m   1651\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[1;32m   1652\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1653\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m   1654\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1655\u001b[0m     head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[1;32m   1656\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[1;32m   1657\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1658\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1659\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1660\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1661\u001b[0m )\n\u001b[1;32m   1663\u001b[0m sequence_output \u001b[39m=\u001b[39m decoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1665\u001b[0m \u001b[39m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:1040\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     layer_outputs \u001b[39m=\u001b[39m checkpoint(\n\u001b[1;32m   1028\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m   1029\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[39mNone\u001b[39;00m,  \u001b[39m# past_key_value is always None with gradient checkpointing\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m     )\n\u001b[1;32m   1039\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1040\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m   1041\u001b[0m         hidden_states,\n\u001b[1;32m   1042\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1043\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m   1044\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1045\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1046\u001b[0m         encoder_decoder_position_bias\u001b[39m=\u001b[39;49mencoder_decoder_position_bias,\n\u001b[1;32m   1047\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m   1048\u001b[0m         cross_attn_layer_head_mask\u001b[39m=\u001b[39;49mcross_attn_layer_head_mask,\n\u001b[1;32m   1049\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m   1050\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1051\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1052\u001b[0m     )\n\u001b[1;32m   1054\u001b[0m \u001b[39m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[39m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:673\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    671\u001b[0m     self_attn_past_key_value, cross_attn_past_key_value \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer[\u001b[39m0\u001b[39;49m](\n\u001b[1;32m    674\u001b[0m     hidden_states,\n\u001b[1;32m    675\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    676\u001b[0m     position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    677\u001b[0m     layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m    678\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    679\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    680\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    681\u001b[0m )\n\u001b[1;32m    682\u001b[0m hidden_states, present_key_value_state \u001b[39m=\u001b[39m self_attention_outputs[:\u001b[39m2\u001b[39m]\n\u001b[1;32m    683\u001b[0m attention_outputs \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m2\u001b[39m:]  \u001b[39m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:579\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    569\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    570\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    577\u001b[0m ):\n\u001b[1;32m    578\u001b[0m     normed_hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 579\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mSelfAttention(\n\u001b[1;32m    580\u001b[0m         normed_hidden_states,\n\u001b[1;32m    581\u001b[0m         mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    582\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    583\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m    584\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m    585\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    586\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    587\u001b[0m     )\n\u001b[1;32m    588\u001b[0m     hidden_states \u001b[39m=\u001b[39m hidden_states \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(attention_output[\u001b[39m0\u001b[39m])\n\u001b[1;32m    589\u001b[0m     outputs \u001b[39m=\u001b[39m (hidden_states,) \u001b[39m+\u001b[39m attention_output[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:509\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    504\u001b[0m value_states \u001b[39m=\u001b[39m project(\n\u001b[1;32m    505\u001b[0m     hidden_states, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv, key_value_states, past_key_value[\u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    506\u001b[0m )\n\u001b[1;32m    508\u001b[0m \u001b[39m# compute scores\u001b[39;00m\n\u001b[0;32m--> 509\u001b[0m scores \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmatmul(\n\u001b[1;32m    510\u001b[0m     query_states, key_states\u001b[39m.\u001b[39;49mtranspose(\u001b[39m3\u001b[39;49m, \u001b[39m2\u001b[39;49m)\n\u001b[1;32m    511\u001b[0m )  \u001b[39m# equivalent of torch.einsum(\"bnqd,bnkd->bnqk\", query_states, key_states), compatible with onnx op>9\u001b[39;00m\n\u001b[1;32m    513\u001b[0m \u001b[39mif\u001b[39;00m position_bias \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    514\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_relative_attention_bias:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 23.63 GiB total capacity; 20.63 GiB already allocated; 54.50 MiB free; 20.73 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(optuna_objective, show_progress_bar=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "339c1ec44efa671d0c0aa472f92368e3220a4c3534888d9daac06fdbcd7c45f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
