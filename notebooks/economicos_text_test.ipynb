{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WigXlQ457KM7"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -U optuna pytorch_lightning==1.8.5.post0 rouge-score transformers sentencepiece pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "NVb5ZoMf7KM9",
        "outputId": "db5a11c7-49b0-4bea-ca6a-30fa8b7b1b32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(22059, 17)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>description</th>\n",
              "      <th>price</th>\n",
              "      <th>property_type</th>\n",
              "      <th>transaction_type</th>\n",
              "      <th>state</th>\n",
              "      <th>county</th>\n",
              "      <th>publication_date</th>\n",
              "      <th>rooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>m_built</th>\n",
              "      <th>m_size</th>\n",
              "      <th>source</th>\n",
              "      <th>title</th>\n",
              "      <th>address</th>\n",
              "      <th>owner</th>\n",
              "      <th>_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>521501</th>\n",
              "      <td>https://www.economicos.cl/propiedades/departam...</td>\n",
              "      <td>Gran departamento a la venta en el Plan de Vin...</td>\n",
              "      <td>$ 230.000.000</td>\n",
              "      <td>Departamento</td>\n",
              "      <td>Venta</td>\n",
              "      <td>Valparaíso</td>\n",
              "      <td>Viña del Mar</td>\n",
              "      <td>2022-02-23 00:00:19</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>El Mercurio</td>\n",
              "      <td>Departamento en Venta en Viña del Mar 3 dormit...</td>\n",
              "      <td>Plan de Viña del mar Viña del Mar, Valparaíso</td>\n",
              "      <td>Mi llave</td>\n",
              "      <td>7308.062513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>587134</th>\n",
              "      <td>https://www.economicos.cl/propiedades/local-o-...</td>\n",
              "      <td>Casa/Local Comercial, Chillán Valor: 7500 UF ...</td>\n",
              "      <td>7.500 UF</td>\n",
              "      <td>Local o Casa comercial</td>\n",
              "      <td>Venta</td>\n",
              "      <td>Biobío</td>\n",
              "      <td>Chillán</td>\n",
              "      <td>2022-02-23 08:07:00</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>315.0</td>\n",
              "      <td>327.0</td>\n",
              "      <td>El Mercurio</td>\n",
              "      <td>Local o Casa comercial en Venta en Chillán 3 d...</td>\n",
              "      <td>Propiedad comercial en Venta Chillán Chillán, ...</td>\n",
              "      <td>Agente 365</td>\n",
              "      <td>7500.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>591505</th>\n",
              "      <td>https://www.economicos.cl/propiedades/departam...</td>\n",
              "      <td>DEPTO. MEJOR BARRIO DE VITACURA - 3 DORMITORIO...</td>\n",
              "      <td>9.720 UF</td>\n",
              "      <td>Departamento</td>\n",
              "      <td>Venta</td>\n",
              "      <td>Metropolitana de Santiago</td>\n",
              "      <td>Vitacura</td>\n",
              "      <td>2022-02-23 00:00:28</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>El Mercurio</td>\n",
              "      <td>Departamento en Venta en Vitacura 3 dormitorio...</td>\n",
              "      <td>Calle Navidad / Las Nieves Vitacura, Metropoli...</td>\n",
              "      <td>Nexxos</td>\n",
              "      <td>9720.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      url  \\\n",
              "521501  https://www.economicos.cl/propiedades/departam...   \n",
              "587134  https://www.economicos.cl/propiedades/local-o-...   \n",
              "591505  https://www.economicos.cl/propiedades/departam...   \n",
              "\n",
              "                                              description          price  \\\n",
              "521501  Gran departamento a la venta en el Plan de Vin...  $ 230.000.000   \n",
              "587134  Casa/Local Comercial, Chillán Valor: 7500 UF ...       7.500 UF   \n",
              "591505  DEPTO. MEJOR BARRIO DE VITACURA - 3 DORMITORIO...       9.720 UF   \n",
              "\n",
              "                 property_type transaction_type                      state  \\\n",
              "521501            Departamento            Venta                 Valparaíso   \n",
              "587134  Local o Casa comercial            Venta                     Biobío   \n",
              "591505            Departamento            Venta  Metropolitana de Santiago   \n",
              "\n",
              "              county    publication_date  rooms  bathrooms  m_built  m_size  \\\n",
              "521501  Viña del Mar 2022-02-23 00:00:19    3.0        2.0    150.0   300.0   \n",
              "587134       Chillán 2022-02-23 08:07:00    3.0        5.0    315.0   327.0   \n",
              "591505      Vitacura 2022-02-23 00:00:28    3.0        2.0    100.0   115.0   \n",
              "\n",
              "             source                                              title  \\\n",
              "521501  El Mercurio  Departamento en Venta en Viña del Mar 3 dormit...   \n",
              "587134  El Mercurio  Local o Casa comercial en Venta en Chillán 3 d...   \n",
              "591505  El Mercurio  Departamento en Venta en Vitacura 3 dormitorio...   \n",
              "\n",
              "                                                  address        owner  \\\n",
              "521501      Plan de Viña del mar Viña del Mar, Valparaíso     Mi llave   \n",
              "587134  Propiedad comercial en Venta Chillán Chillán, ...   Agente 365   \n",
              "591505  Calle Navidad / Las Nieves Vitacura, Metropoli...       Nexxos   \n",
              "\n",
              "             _price  \n",
              "521501  7308.062513  \n",
              "587134  7500.000000  \n",
              "591505  9720.000000  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "#.replace(to_replace=\"-1\", value=np.nan)\n",
        "df = pd.read_parquet('../datasets/economicos/synth/split/train.parquet').replace(to_replace=\"None\", value=np.nan).replace(to_replace=-1, value=np.nan)\n",
        "display(df.shape)\n",
        "\n",
        "CHAR_SEP = \" \"\n",
        "df.sample(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'text': ['Describe', '2022-07-21 precio 4.680 UF tipo Departamento transacción Venta región Metropolitana de Santiago comuna Providencia dormitorios 1.0 baños 1.0 constuidos 40.0 terreno 49.0 precio_real 4680.0'], 'target': 'Se Vende Departamento 1 Dorm. Diego de Almagro 2163. Providencia. Metro Inés de Suárez IMPECABLE, IDEAL INVERSIONISTAS! Incluye ESTACIONAMIENTO Y BODEGA.  - Descripción Departamento: Año 2016 / Constructora Pebal  - 40 m2 útiles - 49 m2 totales, gran terraza - Amplio Dormitorio Principal en suite con closet. - Cocina encimera, mesón granito. - Conexión para lavadora. - Piso 3 de 7. - Orientación Oriente.  Gastos comunes $100.000 aprox. Contribuciones $48.000.-  * Descripción áreas comunes: - Sala multiuso, Gimnasio, Lavandería, Estacionamiento de visitas, Conserjería 24/7  VENDE Y ASESORA ARCO GESTION INMOBILIARIA Agente encargado Carol Mancilla 9.48586901'}\n"
          ]
        }
      ],
      "source": [
        "def convert(row):\n",
        "    return {\n",
        "        \"text\": [\"Describe\", f\"\"\"{row.publication_date.strftime('%Y-%m-%d')}\n",
        "precio {row.price}\n",
        "tipo {row.property_type}\n",
        "transacción {row.transaction_type}\n",
        "región {row.state}\n",
        "comuna {row.county}\n",
        "dormitorios {row.rooms}\n",
        "baños {row.rooms}\n",
        "constuidos {row.m_built}\n",
        "terreno {row.m_size}\n",
        "precio_real {row._price}\"\"\".replace(\"\\n\", \" \")],\n",
        "        \"target\": row.description\n",
        "        }\n",
        "\n",
        "print(\n",
        "    df.sample(1).apply(convert, axis=1).iloc[-1]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "MxDRMWrT7KM_",
        "outputId": "b91151da-aeb9-49c4-9a13-b20adbc61112"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16121</th>\n",
              "      <td>[Describe, 2022-07-21 precio 120 UF tipo Depar...</td>\n",
              "      <td>Departamento en condominio con espectacular á...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6947</th>\n",
              "      <td>[Describe, 2019-11-22 precio 11.190 UF tipo Ca...</td>\n",
              "      <td>Casa de dos pisos en barrio tranquilo, con ori...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9752</th>\n",
              "      <td>[Describe, 2022-02-23 precio 19.999 UF tipo De...</td>\n",
              "      <td>Exclusivo condominio. Precioso departamento do...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  \\\n",
              "16121  [Describe, 2022-07-21 precio 120 UF tipo Depar...   \n",
              "6947   [Describe, 2019-11-22 precio 11.190 UF tipo Ca...   \n",
              "9752   [Describe, 2022-02-23 precio 19.999 UF tipo De...   \n",
              "\n",
              "                                                  target  \n",
              "16121  Departamento en condominio con espectacular á...  \n",
              "6947   Casa de dos pisos en barrio tranquilo, con ori...  \n",
              "9752   Exclusivo condominio. Precioso departamento do...  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_text = pd.DataFrame(df.apply(convert, axis=1).to_list())\n",
        "df_text.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YeWDE1mI7KNA"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "from argparse import ArgumentParser\n",
        "from os.path import join, isfile\n",
        "from os import listdir\n",
        "import optuna\n",
        "from optuna.integration import PyTorchLightningPruningCallback\n",
        "import pandas as pd\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from rouge_score import rouge_scorer\n",
        "import shutil\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import  DataLoader, RandomSampler, SequentialSampler #Dataset,\n",
        "from transformers import get_linear_schedule_with_warmup, AdamW\n",
        "# Importing the T5 modules from huggingface/transformers\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "38Km3oVD7KNB"
      },
      "outputs": [],
      "source": [
        "class MetricsCallback(pl.Callback):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.metrics = []\n",
        "\n",
        "    def on_validation_end(self, trainer, pl_module):\n",
        "        self.metrics.append(trainer.callback_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_BEznZWG7KNB"
      },
      "outputs": [],
      "source": [
        "CHAR_SEP = \" \"\n",
        "MAX_SRC_LEN = 150\n",
        "MAX_TGT_LEN = 720\n",
        "from functools import partial\n",
        "\n",
        "class T5Finetuner(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, args, df, batch_size=8):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.args = args\n",
        "        self.model = T5ForConditionalGeneration.from_pretrained(self.args.model)\n",
        "        self.tokenizer = T5Tokenizer.from_pretrained(self.args.model)\n",
        "        self.data = df\n",
        "        #self.scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "        self.batch_size = batch_size\n",
        "        self.decode = partial(self.tokenizer.decode, skip_special_tokens=True)\n",
        "\n",
        "    def _encode_text(self, text_input, target):\n",
        "      ctext = str(text_input)\n",
        "      ctext = CHAR_SEP.join(ctext.split())\n",
        "      target = str(target) #summarized text\n",
        "      target = CHAR_SEP.join(target.split())\n",
        "      source = self.tokenizer.batch_encode_plus([ctext], \n",
        "                                                max_length= MAX_SRC_LEN, \n",
        "                                                truncation=True,\n",
        "                                                padding='max_length',\n",
        "                                                return_tensors='pt')\n",
        "      target = self.tokenizer.batch_encode_plus([target], \n",
        "                                                max_length=MAX_TGT_LEN,\n",
        "                                                truncation=True,\n",
        "                                                padding='max_length',\n",
        "                                                return_tensors='pt')\n",
        "      y = target['input_ids']\n",
        "      target_id = y[:, :-1].contiguous()\n",
        "      target_label = y[:, 1:].clone().detach()\n",
        "      target_label[y[:, 1:] == self.tokenizer.pad_token_id] = -100 #in case the labels are not provided, empty string\n",
        "      return source['input_ids'], source['attention_mask'], target_id, target_label\n",
        "    \n",
        "    def encode_text(self, text, target):\n",
        "        source = self.tokenizer.batch_encode_plus([text], \n",
        "                                                max_length= MAX_SRC_LEN, \n",
        "                                                truncation=True,\n",
        "                                                padding='max_length',\n",
        "                                                return_tensors='pt')\n",
        "        target = self.tokenizer.batch_encode_plus([target], \n",
        "                                                max_length=MAX_TGT_LEN,\n",
        "                                                truncation=True,\n",
        "                                                padding='max_length',\n",
        "                                                return_tensors='pt')\n",
        "        y = target['input_ids']\n",
        "        target_id = y[:, :-1].contiguous()\n",
        "        target_label = y[:, 1:].clone().detach()\n",
        "        target_label[y[:, 1:] == self.tokenizer.pad_token_id] = -100 #in case the labels are not provided, empty string\n",
        "        return source['input_ids'], source['attention_mask'], target_id, target_label\n",
        "\n",
        "    \n",
        "    def prepare_df(self, df):\n",
        "        source_ids, source_masks, target_ids, target_labels = [], [], [], [] \n",
        "        for _, row in df.iterrows():\n",
        "            source_id, source_mask, target_id, target_label = self.encode_text(row.text, row.target)\n",
        "            source_ids.append(source_id)\n",
        "            source_masks.append(source_mask)\n",
        "            target_ids.append(target_id)\n",
        "            target_labels.append(target_label)\n",
        "\n",
        "        # Convert the lists into tensors\n",
        "        source_ids = torch.cat(source_ids, dim=0)\n",
        "        source_masks = torch.cat(source_masks, dim=0)\n",
        "        target_ids = torch.cat(target_ids, dim=0)\n",
        "        target_labels = torch.cat(target_labels, dim=0)\n",
        "        # splitting the data to train, validation, and test\n",
        "        return TensorDataset(source_ids, source_masks, target_ids, target_labels)\n",
        "    \n",
        "    def prepare_data(self):\n",
        "        # splitting the data to train, validation, and test\n",
        "        data = self.prepare_df(self.data)\n",
        "        train_size, val_size = int(0.8 * len(data)), int(0.1 * len(data))\n",
        "        test_size = len(data) - (train_size + val_size)\n",
        "        self.train_dat, self.val_dat, self.test_dat = \\\n",
        "            random_split(data, [train_size, val_size, test_size])\n",
        "    \n",
        "    def forward(self, batch, batch_idx):\n",
        "        source_ids, source_mask, target_ids, target_labels = batch[:4]\n",
        "        return self.model(input_ids = source_ids, attention_mask = source_mask, \n",
        "                          decoder_input_ids=target_ids, labels=target_labels)\n",
        "        \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss = self(batch, batch_idx)[0]\n",
        "        return {'loss': loss, 'log': {'train_loss': loss}}\n",
        "    \n",
        "    def predict_step(self, batch, batch_idx: int, dataloader_idx: int = 0):\n",
        "        return self(batch, batch_idx)\n",
        "        return \" \".join(map(self.decode, y_hat))\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss = self(batch, batch_idx)[0]\n",
        "        return {'loss': loss, 'val_loss': loss}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        loss = sum([o['loss'] for o in outputs]) / len(outputs)\n",
        "        out = {'val_loss': loss}\n",
        "        return {**out, 'log': out}\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        loss = self(batch, batch_idx)[0]\n",
        "        return {'loss': loss}\n",
        "\n",
        "    def test_epoch_end(self, outputs):\n",
        "        loss = sum([o['loss'] for o in outputs]) / len(outputs)\n",
        "        out = {'test_loss': loss}\n",
        "        return {**out, 'log': out}\n",
        "    \n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_dat, batch_size=self.batch_size,\n",
        "                          num_workers=4, sampler=RandomSampler(self.train_dat))\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_dat, batch_size=self.args.bs, num_workers=4,\n",
        "                          sampler=SequentialSampler(self.val_dat))\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_dat, batch_size=self.args.bs, num_workers=4,\n",
        "                          sampler=SequentialSampler(self.test_dat))    \n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = AdamW(self.model.parameters(), lr=self.args.lr, eps=1e-4)\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer, num_warmup_steps=0,\n",
        "            num_training_steps=self.args.max_epochs * len(self.train_dat))\n",
        "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}\n",
        "    \n",
        "    def generate_summary(self, ctext, summ_len=150, text='', beam_search=2, repetition_penalty=2.5):\n",
        "        source_id, source_mask, target_id, target_label = self.encode_text(ctext, text)\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            generated_ids = self.model.generate(\n",
        "                input_ids = source_id,\n",
        "                attention_mask = source_mask, \n",
        "                max_length=summ_len, \n",
        "                truncation=True,\n",
        "                num_beams=beam_search,\n",
        "                repetition_penalty=repetition_penalty, \n",
        "                length_penalty=1.0, \n",
        "                early_stopping=True\n",
        "                )\n",
        "            prediction = [self.tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
        "        if len(text) > 0:\n",
        "            target = [self.tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in target_id]\n",
        "            scores = self.scorer.score(target[0], prediction[0])\n",
        "            return prediction, scores\n",
        "        else:\n",
        "            return prediction\n",
        "        \n",
        "\n",
        "    def save_core_model(self):\n",
        "        store_path = join(self.args.output, self.args.name, 'core')\n",
        "        self.model.save_pretrained(store_path)\n",
        "        self.tokenizer.save_pretrained(store_path)\n",
        "        \n",
        "    @staticmethod\n",
        "    def add_model_specific_args(parent_parser):\n",
        "        p = ArgumentParser(parents=[parent_parser], add_help=False)\n",
        "        p.add_argument('-m', '--model', type=str, default='t5-base',\n",
        "                       help='name of the model or the path pointing to it')\n",
        "        p.add_argument('--bs', '--batch_size', type=int, default=2)\n",
        "        p.add_argument('--source_len', type=int, default=120)\n",
        "        p.add_argument('--summ_len', type=int, default=700)\n",
        "        return p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "INWGt3Rd7KNC"
      },
      "outputs": [],
      "source": [
        "def default_args():\n",
        "    p = ArgumentParser()\n",
        "    p.add_argument('-p', '--path', type=str,  \n",
        "                   default='/content/gdrive/My Drive/Colab Notebooks/data/text_summarization_t5/news_summary.csv',\n",
        "                  help='path to the data file')\n",
        "    p.add_argument('-o', '--output', type=str, default='/tmp/tpu-template',\n",
        "                  help='path to the output directory for storing the model')\n",
        "    p.add_argument('-n', '--name', type=str, default='google/t5-v1_1-xxl',\n",
        "                  help='this name will be used on tensorboard for the model')\n",
        "    p.add_argument('-t', '--trials', type=int, default=1,\n",
        "                  help='number of trials for hyperparameter search')\n",
        "    p.add_argument('--seed', type=int, default=0, help='randomization seed')\n",
        "    p = T5Finetuner.add_model_specific_args(p)\n",
        "    p = pl.Trainer.add_argparse_args(p)\n",
        "    args,_ = p.parse_known_args()\n",
        "    args.max_epochs = 2\n",
        "    return args\n",
        "\n",
        "def default_args():\n",
        "    p = ArgumentParser()\n",
        "    args,_ = p.parse_known_args()\n",
        "    args.max_epochs = 2\n",
        "    #args.model = \"google/flan-t5-small\"\n",
        "    #args.model = \"google/flan-t5-xl\"\n",
        "    args.model = \"google/flan-t5-large\"\n",
        "    #args.model = \"google/flan-t5-base\"\n",
        "    args.output = f\"./{args.model.replace('/','_')}\"\n",
        "    args.name = \"DESCRIPCION_PROPIEDADES\"\n",
        "    args.bs = 1 # batch size\n",
        "    return args\n",
        "\n",
        "def optuna_objective(trial):\n",
        "    args = default_args()\n",
        "    # sampling the hyperparameters\n",
        "    args.lr = trial.suggest_categorical(\"lr\", [1e-6, 5e-6, 1e-5, 5e-5, 1e-4])\n",
        "    # setting up the right callbacks\n",
        "    cp_callback = pl.callbacks.ModelCheckpoint(\n",
        "        join(args.output, args.name, f\"trial_{trial.number}\", \"{epoch}\"),\n",
        "        monitor=\"val_loss\", mode=\"min\")\n",
        "    pr_callback = PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")\n",
        "    metrics_callback = MetricsCallback()\n",
        "    summarizer = T5Finetuner(args, df_text)         # loading the model\n",
        "    trainer = pl.Trainer.from_argparse_args(      # loading the trainer\n",
        "        args, \n",
        "        accelerator=\"gpu\",\n",
        "        devices=1,\n",
        "        default_root_dir=args.output, gradient_clip_val=1.0,\n",
        "        #checkpoint_callback=cp_callback,\n",
        "        callbacks=[metrics_callback],\n",
        "        #early_stop_callback=pr_callback, \n",
        "        num_sanity_val_steps=-1,\n",
        "        #auto_scale_batch_size=\"power\",\n",
        "        # select TensorBoad or Wandb logger\n",
        "        logger=TensorBoardLogger(join(args.output, 'logs'), name=args.name, version=f'trial_{trial.number}')\n",
        "        )\n",
        "  \n",
        "    trainer.fit(summarizer)                       # fitting the model\n",
        "    trainer.test(summarizer)                      # testing the model\n",
        "    return min([x['val_loss'].item() for x in metrics_callback.metrics])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8Tv_jey87KND"
      },
      "outputs": [],
      "source": [
        "#NEW_MODEL=\"/home/gvillarroel/dev/synthetic-data-for-text/notebooks/google_flan-t5-base/logs/DESCRIPCION_PROPIEDADES/trial_0/checkpoints/epoch=1-step=436696.ckpt\"\n",
        "NEW_MODEL = \"/home/gvillarroel/dev/synthetic-data-for-text/notebooks/google_flan-t5-large/logs/DESCRIPCION_PROPIEDADES/trial_0/checkpoints/epoch=1-step=873392.ckpt\"\n",
        "new_model = T5Finetuner.load_from_checkpoint(NEW_MODEL)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Describe 2022-07-21 precio 22.000 UF tipo Casa transacción Venta región Araucanía comuna Temuco dormitorios 5.0 baños 5.0 constuidos 360.0 terreno 5000.0 precio_real 22000.0'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'- Especialistas in art, culture y music. ----- Ubicados: Ibarra 910 Oficina A-614 Concepción; Fono (09) 88217303/ +56984723607 Mail (jdistribucionist@gmail.com); mosa casa en Condominio Valle de la Araucana, Temuco. Casa con 5 dormitorios 3 baos Sala estar Living comedor separados Piscina Quincho Terraza Bodegas Estupendamente cuidadizada Ubicada al norte del condomino La propiedad consta: Primer piso Hall acceso living Comedin Comodo dormitor'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'Se vende casa en Lomas Del Carmen, Temuco. Se vende casa 360m2 construidos, 5000m2 terreno en exclusivo Condominio Lomas del Carmen en Temuco. Propiedad estilo chilena con influencia colonia alemana rural. 2 niveles más un altillo para uso recreacional, 5 dormitorios, 5 baños, más casa de huéspedes de 82 m2. Lujosa, amplia y cómoda casa para disfrutar en familia. Condominio con seguridad las 24hrs del día.'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from textwrap import wrap\n",
        "from numpy import random\n",
        "\n",
        "new_model.model.eval()\n",
        "new_model.model.cuda()\n",
        "#record = df_text.sample(1).iloc[0]\n",
        "def gen_new_text(record):\n",
        "    #encoded = new_model.tokenizer.batch_encode_plus(record.text, max_length= MAX_SRC_LEN, truncation=False,padding=False,return_tensors='pt')\n",
        "    encoded = new_model.tokenizer.batch_encode_plus(record.text, \n",
        "                                                max_length= 120, \n",
        "                                                truncation=True,\n",
        "                                                padding='max_length',\n",
        "                                                return_tensors='pt')\n",
        "    #encoded = new_model.tokenizer(\"<sep>\".join(record.text), return_tensors=\"pt\")\n",
        "    \n",
        "    max_length= random.randint(200, 600)\n",
        "    min_length = random.randint(20, max_length-5)\n",
        "    min_length=60\n",
        "    max_length=100\n",
        "    input_ids =encoded['input_ids'].cuda() \n",
        "    att = encoded['attention_mask'].cuda()\n",
        "    y_hat = new_model.model.generate(\n",
        "        inputs= input_ids,\n",
        "        attention_mask=att,\n",
        "        num_beams=1,\n",
        "        min_length=min_length,\n",
        "        max_length=max_length,\n",
        "        repetition_penalty=5.5,\n",
        "        length_penalty=0.1,\n",
        "        early_stopping=True,\n",
        "        temperature=random.random(),\n",
        "        use_cache=False,\n",
        "        top_p=random.random(),\n",
        "        #top_k=0,\n",
        "        do_sample=True\n",
        "    )\n",
        "    del input_ids\n",
        "    del att\n",
        "    return \" \".join([new_model.tokenizer.decode(gen_id, skip_special_tokens=True) for gen_id in y_hat])\n",
        "\n",
        "display(\" \".join(record.text))\n",
        "display(gen_new_text(record))\n",
        "display(record.target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "#import swifter\n",
        "data_g  = df_text.head(1000).apply(gen_new_text, axis=1)\n",
        "df_new_text = df_text.head(1000).assign(generated=data_g)\n",
        "df_new_text.to_parquet(\"m2.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import polars as prs\n",
        "df_text.to_parquet(\"text.parquet\")\n",
        "df_p_text = prs.read_parquet(\"text.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gen_new_text_p(record):\n",
        "    #encoded = new_model.tokenizer.batch_encode_plus(record.text, max_length= MAX_SRC_LEN, truncation=False,padding=False,return_tensors='pt')\n",
        "    encoded = new_model.tokenizer.batch_encode_plus(record[0], \n",
        "                                                max_length= 120, \n",
        "                                                truncation=True,\n",
        "                                                padding='max_length',\n",
        "                                                return_tensors='pt')\n",
        "    #encoded = new_model.tokenizer(\"<sep>\".join(record.text), return_tensors=\"pt\")\n",
        "    \n",
        "    max_length= random.randint(200, 600)\n",
        "    min_length = random.randint(20, max_length-5)\n",
        "    input_ids =encoded['input_ids'].cuda() \n",
        "    att = encoded['attention_mask'].cuda()\n",
        "    y_hat = new_model.model.generate(\n",
        "        inputs= input_ids,\n",
        "        attention_mask=att,\n",
        "        num_beams=1,\n",
        "        min_length=min_length,\n",
        "        max_length=max_length,\n",
        "        repetition_penalty=5.5,\n",
        "        length_penalty=0.1,\n",
        "        early_stopping=True,\n",
        "        temperature=random.random(),\n",
        "        use_cache=False,\n",
        "        top_p=random.random(),\n",
        "        top_k=0,\n",
        "        do_sample=True\n",
        "    )\n",
        "    del input_ids\n",
        "    del att\n",
        "    return \" \".join([new_model.tokenizer.decode(gen_id, skip_special_tokens=True) for gen_id in y_hat])\n",
        "#df_out = df_p_text.head(1000).apply(gen_new_text_p)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "syn",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15 (main, Nov  5 2022, 10:07:01) \n[GCC 11.3.0]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "339c1ec44efa671d0c0aa472f92368e3220a4c3534888d9daac06fdbcd7c45f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
