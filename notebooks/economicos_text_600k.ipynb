{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install optuna pytorch_lightning rouge-score transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(545870, 17)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#.replace(to_replace=\"-1\", value=np.nan)\n",
    "df = pd.read_parquet('../datasets/economicos/synthb/split/train.parquet')\n",
    "#.replace(to_replace=\"None\", value=np.nan).replace(to_replace=-1, value=np.nan)\n",
    "display(df.shape)\n",
    "df.sample(3)\n",
    "CHAR_SEP = \" \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['<fecha, 2020-09-23> <precio, 15500 UF> <tipo, Departamento> <transacción, Venta> <región, Metropolitana de Santiago> <comuna, Providencia> <dormitorios, 2.0> <baños, 2.0> <construidos, 260.0> <terreno, 5000.0> <precio_real, 15500.0> <titulo, PENTHOUSE DÚPLEX 260 mt2 LOTA / LUIS THAYER OJEDA> <dirección, LUIS THAYER OJEDA 615 Providencia, Metropolitana de Santiago>',\n",
       "  'descripción de esta publicación'],\n",
       " 'target': 'Última y Gran Oportunidad. Espectacular y Único Penthouse Dúplex recién remodelado 100% todo nuevo sin uso.\\nMaravilloso departamento pisos 14 y 15, la mejor ubicación de Providencia, orientación: nororiente / norte / poniente y sur. Privilegiada vista panorámica asegurada a todo Santiago, rodeado de áreas verdes y arboles añosos, recién remodelado 100% (instalación eléctrica nueva 40 amperes, instalación sanitaria, gas y agua, ventanas con termo paneles winko, pisos: porcelanatos, cerámicas y maderas, pintura de muros realizada por un artista, foto murales en living y suite, grifería alemana) 260 mt2, grandes espacios, living 60mt2, y comedor 24mt2 independientes, cocina italiana equipada 50mt2 equipada, logia, 1 dormitorio: suite 64mts con closet de diseño de 70cm x 8mts, 1 dormitorio ó escritorio 10mt2, cortinas roller holandesas, nuevas e instaladas, gran terraza 40mt2 con toldos franceses nuevos a control remoto con lona española, 3 baños 18mt2 + otros espacios, calefacción central a gas natural individual con climatizador, gran bodega subterránea con closet y 2 amplios estacionamientos cubiertos en primer subterráneo.\\nVENDE DUEÑO DIRECTO\\n'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert(row):\n",
    "    return {\n",
    "        \"text\": [\n",
    "            f\"\"\"<fecha, {(pd.Timestamp('2017-12-01') +  pd.DateOffset(int(row.publication_date or 0))).strftime('%Y-%m-%d')}>\n",
    "<precio, {row.price}>\n",
    "<tipo, {row.property_type}>\n",
    "<transacción, {row.transaction_type}>\n",
    "<región, {row.state}>\n",
    "<comuna, {row.county}>\n",
    "<dormitorios, {row.rooms or -1}>\n",
    "<baños, {row.rooms or -1}>\n",
    "<construidos, {row.m_built or -1}>\n",
    "<terreno, {row.m_size or -1}>\n",
    "<precio_real, {row._price}>\n",
    "<titulo, {row.title}>\n",
    "<dirección, {row.address}>\"\"\".replace(\"\\n\", \" \"),\n",
    "\"descripción de esta publicación\"],\n",
    "\n",
    "\"target\": row.description\n",
    "        }\n",
    "\n",
    "display(\n",
    "    df.sample(1).apply(convert, axis=1).iloc[-1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190693</th>\n",
       "      <td>[&lt;fecha, 2018-11-25&gt; &lt;precio, $ 100.000&gt; &lt;tipo...</td>\n",
       "      <td>un dormitorio con closets, comedor,baño con c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403286</th>\n",
       "      <td>[&lt;fecha, 2019-03-07&gt; &lt;precio, $&gt; &lt;tipo, Casa&gt; ...</td>\n",
       "      <td>Vendo casa Quinta Normal, Salvador Gutiérrez ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428363</th>\n",
       "      <td>[&lt;fecha, 2020-01-02&gt; &lt;precio, $ 290.000&gt; &lt;tipo...</td>\n",
       "      <td>Arriendo departamento de dos dormitorios, coci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "190693  [<fecha, 2018-11-25> <precio, $ 100.000> <tipo...   \n",
       "403286  [<fecha, 2019-03-07> <precio, $> <tipo, Casa> ...   \n",
       "428363  [<fecha, 2020-01-02> <precio, $ 290.000> <tipo...   \n",
       "\n",
       "                                                   target  \n",
       "190693  un dormitorio con closets, comedor,baño con c...  \n",
       "403286  Vendo casa Quinta Normal, Salvador Gutiérrez ...  \n",
       "428363  Arriendo departamento de dos dormitorios, coci...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text = pd.DataFrame(df.apply(convert, axis=1).to_list())\n",
    "df_text.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from argparse import ArgumentParser\n",
    "from os.path import join, isfile\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from rouge_score import rouge_scorer\n",
    "import shutil\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import  DataLoader, RandomSampler, SequentialSampler #Dataset,\n",
    "from transformers import get_linear_schedule_with_warmup, AdamW\n",
    "# Importing the T5 modules from huggingface/transformers\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkn = T5Tokenizer.from_pretrained(\"google/t5-v1_1-xxl\")\n",
    "def t2l(row):\n",
    "    text = row.text\n",
    "    target = row.target\n",
    "\n",
    "    return {\"text\": len(tkn(\n",
    "        text\n",
    "        )[\"input_ids\"]),\n",
    "        \"target\": len(tkn(\n",
    "        target\n",
    "        )[\"input_ids\"])}\n",
    "#txttgt = pd.DataFrame(df.apply(convert, axis=1).to_list())\n",
    "#d = pd.DataFrame(txttgt).apply(t2l, axis=1).to_list()\n",
    "#print(pd.DataFrame(d).quantile(0.1))\n",
    "#print(pd.DataFrame(d).quantile(0.96))\n",
    "## in: 12:36\n",
    "## out: 12:528"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gvillarroel/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "def set_seed(seed):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCallback(pl.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.metrics = []\n",
    "\n",
    "    def on_validation_end(self, trainer, pl_module):\n",
    "        self.metrics.append(trainer.callback_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAR_SEP = \" \"\n",
    "MAX_SRC_LEN = 200\n",
    "MAX_TGT_LEN = 720\n",
    "class T5Finetuner(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, args, df, batch_size=8):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.args = args\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(self.args.model)\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(self.args.model)\n",
    "        self.data = df\n",
    "        self.scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def encode_text(self, text, target):\n",
    "        source = self.tokenizer.batch_encode_plus([\"<SEP>\".join(text)], \n",
    "                                                max_length= MAX_SRC_LEN, \n",
    "                                                truncation=True,\n",
    "                                                padding='max_length',\n",
    "                                                return_tensors='pt')\n",
    "        target = self.tokenizer.batch_encode_plus([target], \n",
    "                                                max_length=MAX_TGT_LEN,\n",
    "                                                truncation=True,\n",
    "                                                padding='max_length',\n",
    "                                                return_tensors='pt')\n",
    "        y = target['input_ids']\n",
    "        target_id = y[:, :-1].contiguous()\n",
    "        target_label = y[:, 1:].clone().detach()\n",
    "        target_label[y[:, 1:] == self.tokenizer.pad_token_id] = -100 #in case the labels are not provided, empty string\n",
    "        return source['input_ids'], source['attention_mask'], target_id, target_label\n",
    "\n",
    "        \n",
    "    \n",
    "    def prepare_data(self):\n",
    "        source_ids, source_masks, target_ids, target_labels = [], [], [], [] \n",
    "        for _, row in self.data.iterrows():\n",
    "            source_id, source_mask, target_id, target_label = self.encode_text(row.text, row.target)\n",
    "            source_ids.append(source_id)\n",
    "            source_masks.append(source_mask)\n",
    "            target_ids.append(target_id)\n",
    "            target_labels.append(target_label)\n",
    "\n",
    "        # Convert the lists into tensors\n",
    "        source_ids = torch.cat(source_ids, dim=0)\n",
    "        source_masks = torch.cat(source_masks, dim=0)\n",
    "        target_ids = torch.cat(target_ids, dim=0)\n",
    "        target_labels = torch.cat(target_labels, dim=0)\n",
    "        # splitting the data to train, validation, and test\n",
    "        data = TensorDataset(source_ids, source_masks, target_ids, target_labels)\n",
    "        train_size, val_size = int(0.8 * len(data)), int(0.1 * len(data))\n",
    "        test_size = len(data) - (train_size + val_size)\n",
    "        self.train_dat, self.val_dat, self.test_dat = \\\n",
    "            random_split(data, [train_size, val_size, test_size])\n",
    "    \n",
    "    def forward(self, batch, batch_idx):\n",
    "        source_ids, source_mask, target_ids, target_labels = batch[:4]\n",
    "        return self.model(input_ids = source_ids, attention_mask = source_mask, \n",
    "                          decoder_input_ids=target_ids, labels=target_labels)\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self(batch, batch_idx)[0]\n",
    "        return {'loss': loss, 'log': {'train_loss': loss}}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self(batch, batch_idx)[0]\n",
    "        return {'loss': loss, 'val_loss': loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        loss = sum([o['loss'] for o in outputs]) / len(outputs)\n",
    "        out = {'val_loss': loss}\n",
    "        return {**out, 'log': out}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss = self(batch, batch_idx)[0]\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        loss = sum([o['loss'] for o in outputs]) / len(outputs)\n",
    "        out = {'test_loss': loss}\n",
    "        return {**out, 'log': out}\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dat, batch_size=self.batch_size,\n",
    "                          num_workers=4, sampler=RandomSampler(self.train_dat))\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dat, batch_size=self.args.bs, num_workers=4,\n",
    "                          sampler=SequentialSampler(self.val_dat))\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dat, batch_size=self.args.bs, num_workers=4,\n",
    "                          sampler=SequentialSampler(self.test_dat))    \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.model.parameters(), lr=self.args.lr, eps=1e-4)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps=0,\n",
    "            num_training_steps=self.args.max_epochs * len(self.train_dat))\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}\n",
    "    \n",
    "    def generate_summary(self, ctext, summ_len=150, text='', beam_search=2, repetition_penalty=2.5):\n",
    "        source_id, source_mask, target_id, target_label = self.encode_text(ctext, text)\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            generated_ids = self.model.generate(\n",
    "                input_ids = source_id,\n",
    "                attention_mask = source_mask, \n",
    "                max_length=summ_len, \n",
    "                truncation=True,\n",
    "                num_beams=beam_search,\n",
    "                repetition_penalty=repetition_penalty, \n",
    "                length_penalty=1.0, \n",
    "                early_stopping=True\n",
    "                )\n",
    "            prediction = [self.tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "        if len(text) > 0:\n",
    "            target = [self.tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in target_id]\n",
    "            scores = self.scorer.score(target[0], prediction[0])\n",
    "            return prediction, scores\n",
    "        else:\n",
    "            return prediction\n",
    "        \n",
    "\n",
    "    def save_core_model(self):\n",
    "        store_path = join(self.args.output, self.args.name, 'core')\n",
    "        self.model.save_pretrained(store_path)\n",
    "        self.tokenizer.save_pretrained(store_path)\n",
    "        \n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser):\n",
    "        p = ArgumentParser(parents=[parent_parser], add_help=False)\n",
    "        p.add_argument('-m', '--model', type=str, default='t5-base',\n",
    "                       help='name of the model or the path pointing to it')\n",
    "        p.add_argument('--bs', '--batch_size', type=int, default=2)\n",
    "        p.add_argument('--source_len', type=int, default=120)\n",
    "        p.add_argument('--summ_len', type=int, default=700)\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_args():\n",
    "    p = ArgumentParser()\n",
    "    args,_ = p.parse_known_args()\n",
    "    args.max_epochs = 50\n",
    "    args.model = \"google/mt5-base\"\n",
    "    args.output = f\"./B-{args.model.replace('/','_')}\"\n",
    "    args.name = \"DESCRIPCION_PROPIEDADES\"\n",
    "    args.bs = 1 # batch size\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type mt5 to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 20\u001b[0m\n\u001b[1;32m      9\u001b[0m summarizer \u001b[39m=\u001b[39m T5Finetuner(args, df_text)         \u001b[39m# loading the model\u001b[39;00m\n\u001b[1;32m     10\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer\u001b[39m.\u001b[39mfrom_argparse_args(      \u001b[39m# loading the trainer\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     args, \n\u001b[1;32m     12\u001b[0m     accelerator\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpu\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     logger\u001b[39m=\u001b[39mTensorBoardLogger(join(args\u001b[39m.\u001b[39moutput, \u001b[39m'\u001b[39m\u001b[39mlogs\u001b[39m\u001b[39m'\u001b[39m), name\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mname, version\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrial_0\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m     )\n\u001b[0;32m---> 20\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(summarizer)                       \u001b[39m# fitting the model\u001b[39;00m\n\u001b[1;32m     21\u001b[0m trainer\u001b[39m.\u001b[39mtest(summarizer)                      \u001b[39m# testing the model\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:603\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`Trainer.fit()` requires a `LightningModule`, got: \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    602\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 603\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    604\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    605\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     37\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     41\u001b[0m     trainer\u001b[39m.\u001b[39m_call_teardown_hook()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:645\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    638\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    639\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_set_ckpt_path(\n\u001b[1;32m    640\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    641\u001b[0m     ckpt_path,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    642\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    643\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    644\u001b[0m )\n\u001b[0;32m--> 645\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    647\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    648\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1034\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1031\u001b[0m \u001b[39m# SET UP TRAINING\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: setting up strategy environment\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1034\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrategy\u001b[39m.\u001b[39;49msetup_environment()\n\u001b[1;32m   1035\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__setup_profiler()\n\u001b[1;32m   1037\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_setup_hook()  \u001b[39m# allow user to setup lightning_module in accelerator environment\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py:131\u001b[0m, in \u001b[0;36mStrategy.setup_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39m\"\"\"Setup any processes or distributed connections.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \n\u001b[1;32m    127\u001b[0m \u001b[39mThis is called before the LightningModule/DataModule setup hook which allows the user to access the accelerator\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39menvironment before setup is complete.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccelerator\u001b[39m.\u001b[39;49msetup_device(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot_device)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/pytorch_lightning/accelerators/cuda.py:43\u001b[0m, in \u001b[0;36mCUDAAccelerator.setup_device\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mif\u001b[39;00m device\u001b[39m.\u001b[39mtype \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     42\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDevice should be GPU, got \u001b[39m\u001b[39m{\u001b[39;00mdevice\u001b[39m}\u001b[39;00m\u001b[39m instead\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mset_device(device)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/torch/cuda/__init__.py:326\u001b[0m, in \u001b[0;36mset_device\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    324\u001b[0m device \u001b[39m=\u001b[39m _get_device_index(device)\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 326\u001b[0m     torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_cuda_setDevice(device)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/torch/cuda/__init__.py:229\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39menviron:\n\u001b[1;32m    228\u001b[0m     os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mLAZY\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 229\u001b[0m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_cuda_init()\n\u001b[1;32m    230\u001b[0m \u001b[39m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[39m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    233\u001b[0m _tls\u001b[39m.\u001b[39mis_initializing \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."
     ]
    }
   ],
   "source": [
    "args = default_args()\n",
    "# sampling the hyperparameters\n",
    "args.lr = 2e-5\n",
    "# setting up the right callbacks\n",
    "cp_callback = pl.callbacks.ModelCheckpoint(\n",
    "    join(args.output, args.name, f\"trial_0\", \"{epoch}\"),\n",
    "    monitor=\"val_loss\", mode=\"min\")\n",
    "metrics_callback = MetricsCallback()\n",
    "summarizer = T5Finetuner(args, df_text)         # loading the model\n",
    "trainer = pl.Trainer.from_argparse_args(      # loading the trainer\n",
    "    args, \n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    default_root_dir=args.output, gradient_clip_val=1.0,\n",
    "    callbacks=[metrics_callback, cp_callback],\n",
    "    num_sanity_val_steps=-1,\n",
    "    logger=TensorBoardLogger(join(args.output, 'logs'), name=args.name, version=f'trial_0')\n",
    "    )\n",
    "\n",
    "trainer.fit(summarizer)                       # fitting the model\n",
    "trainer.test(summarizer)                      # testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_MODEL=\"/home/gvillarroel/dev/synthetic-data-for-text/notebooks/google_flan-t5-small/logs/DESCRIPCION_PROPIEDADES/trial_0/checkpoints/epoch=1-step=87340.ckpt\"\n",
    "new_model = T5Finetuner.load_from_checkpoint(NEW_MODEL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = new_model.tokenizer.batch_encode_plus([df_text.iloc[200].text], \n",
    "                                                max_length= MAX_SRC_LEN, \n",
    "                                                truncation=True,\n",
    "                                                padding='max_length',\n",
    "                                                return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    3, 30010,     1,   846, 18083, 10106,     3,   102,  7886,    32,\n",
       "          1514,  2226,    32,  9882,   736,    32,  4605,    26,     9,  3017,\n",
       "             9,    75, 12765,  1533,  3483,    26,    32,  5925,    23, 15742,\n",
       "          3144, 29461,  6252,     9,     3,    29,   152, 28349,    23,    32,\n",
       "             7,     3,    29,   152,  4698,     2,    32,     7,     3,    29,\n",
       "           152,  6900,    17,    76, 28594,     3,    29,   152, 10225,    29,\n",
       "            32,     3,    29,   152,     3,   102,  7886,    32,   834,  6644,\n",
       "             3, 11739,    10,     1,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.eval()\n",
    "y_hat = new_model.model.generate(\n",
    "    inputs=encoded['input_ids'],\n",
    "    attention_mask=encoded['attention_mask'],\n",
    "    num_beams=1,\n",
    "    max_length=500,\n",
    "    repetition_penalty=2.5,\n",
    "    length_penalty=1.0,\n",
    "    early_stopping=True,\n",
    "    use_cache=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arriendo casa amoblada, 2 dormitoriOS. 998283509.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([new_model.tokenizer.decode(gen_id, skip_special_tokens=True, clean_up_tokenization_spaces=True) for gen_id in y_hat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m new_model\u001b[39m.\u001b[39;49mtokenizer\u001b[39m.\u001b[39;49mdecode(y_hat\u001b[39m.\u001b[39;49mlogits\u001b[39m.\u001b[39;49msqueeze(), skip_special_tokens\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, clean_up_tokenization_spaces\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3468\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[39m# Convert inputs to python lists\u001b[39;00m\n\u001b[1;32m   3466\u001b[0m token_ids \u001b[39m=\u001b[39m to_py_obj(token_ids)\n\u001b[0;32m-> 3468\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decode(\n\u001b[1;32m   3469\u001b[0m     token_ids\u001b[39m=\u001b[39;49mtoken_ids,\n\u001b[1;32m   3470\u001b[0m     skip_special_tokens\u001b[39m=\u001b[39;49mskip_special_tokens,\n\u001b[1;32m   3471\u001b[0m     clean_up_tokenization_spaces\u001b[39m=\u001b[39;49mclean_up_tokenization_spaces,\n\u001b[1;32m   3472\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   3473\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/transformers/tokenization_utils.py:931\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, spaces_between_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_decode\u001b[39m(\n\u001b[1;32m    922\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    923\u001b[0m     token_ids: List[\u001b[39mint\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    928\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    929\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decode_use_source_tokenizer \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39muse_source_tokenizer\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 931\u001b[0m     filtered_tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_ids_to_tokens(token_ids, skip_special_tokens\u001b[39m=\u001b[39;49mskip_special_tokens)\n\u001b[1;32m    933\u001b[0m     \u001b[39m# To avoid mixing byte-level and unicode for byte-level BPT\u001b[39;00m\n\u001b[1;32m    934\u001b[0m     \u001b[39m# we need to build string separately for added tokens and byte-level tokens\u001b[39;00m\n\u001b[1;32m    935\u001b[0m     \u001b[39m# cf. https://github.com/huggingface/transformers/issues/1133\u001b[39;00m\n\u001b[1;32m    936\u001b[0m     sub_texts \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/envs/syn/lib/python3.9/site-packages/transformers/tokenization_utils.py:906\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.convert_ids_to_tokens\u001b[0;34m(self, ids, skip_special_tokens)\u001b[0m\n\u001b[1;32m    904\u001b[0m tokens \u001b[39m=\u001b[39m []\n\u001b[1;32m    905\u001b[0m \u001b[39mfor\u001b[39;00m index \u001b[39min\u001b[39;00m ids:\n\u001b[0;32m--> 906\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mint\u001b[39;49m(index)\n\u001b[1;32m    907\u001b[0m     \u001b[39mif\u001b[39;00m skip_special_tokens \u001b[39mand\u001b[39;00m index \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mall_special_ids:\n\u001b[1;32m    908\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'list'"
     ]
    }
   ],
   "source": [
    "new_model.tokenizer.decode(y_hat.logits.squeeze(), skip_special_tokens=True, clean_up_tokenization_spaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, d  = new_model.encode_text(\n",
    "        ['Describe',\n",
    " '2018-04-15 precio $ tipo Casa Amoblada transacción Arriendo región Los Lagos comuna nan dormitorios nan baños nan constuidos nan terreno nan precio_real 0.0:'], \"\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "339c1ec44efa671d0c0aa472f92368e3220a4c3534888d9daac06fdbcd7c45f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
