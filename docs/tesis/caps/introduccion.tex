\chapter{Introducción}

Es probable que esta tesis esté desactualizada en el momento de su revisión. Desde la aparición de AlexNet \cite{krizhevsky_imagenet_2012} n 2012, el liderazgo en la clasificación de imágenes ha cambiado al menos 15 veces \cite{noauthor_papers_nodate}. En la esfera de la generación de texto a imágenes, se destacan modelos como DALL-E 2 \cite{noauthor_dalle_nodate}, Google Imagen \cite{noauthor_imagen_nodate} y Stable Diffusion \cite{noauthor_stable_nodate}, todos introducidos en 2022. Para 2023, se anticipa una contienda en el ámbito de la inteligencia artificial enfocada en chatbots, protagonizada por Google y Microsoft \cite{milmo_google_2023, noauthor_microsoft_2023}. En resumen, es un ámbito de constante evolución, que promete seguir innovando con nuevas técnicas y productos, en términos de variedad y calidad.

Enmarcado en la empresa \textbf{Equifax}, a la que se dirige este estudio, es imperativo progresar de manera rápida y efectiva en el empleo de su información para mantenerse a la vanguardia en su industria y competir con otras entidades del sector.


Según el libro \emph{Practical synthetic data generation: balancing privacy and the broad availability of data} \cite{el_emam_practical_2020} los datos sintéticos ofrecen dos beneficios principales:
\begin{enumerate}
    \item Mayor eficiencia en la disponibilidad de datos, y
    \item Mejora en los análisis realizados.
\end{enumerate}

Para \textbf{Equifax}, ambos beneficios son valiosos, aunque inicialmente la eficiencia en la disponibilidad de datos tiene mayor peso. Como se verá posteriormente, la empresa ejerce un control total sobre el acceso a la información y los datos, ya que es necesario proteger su confidencialidad.

El objetivo general de este trabajo es diseñar un mecanismo para generar conjuntos de datos sintéticos estructurados, que contengan textos, y compararlos con sus contrapartes originales utilizando nuevas tecnicas.

\section{Equifax: Contexto y Restricciones}

\textbf{Equifax} es una entidad crediticia multinacional que, junto con Transunion y Experian, conforman los tres burós de crédito más grandes a nivel global. La compañía cuenta con equipos de desarrollo en Estados Unidos, India, Irlanda y Chile y opera en más de 24 países. El negocio principal de Equifax es la generación de conocimientos a partir de la data recolectada, que incluye información crediticia, servicios básicos, autos, mercadotecnia, Twitter, revistas, datos demográficos, entre otros. El principal reto tecnológico de la compañía es proteger la privacidad de estos datos. El segundo es realizar predicciones significativas para el mercado utilizando los datos acumulados.
Los datos son uno de los activos más importantes, si no el más importante, de la compañía.

El equipo \textbf{Keying and Linking} de Equifax se encarga de identificar entidades y establecer sus relaciones dentro de los diferentes conjuntos de datos. Esta tarea debe aplicarse a cada entidad dentro de la compañía y a través de todas las zonas geográficas. La identificación de entidades, o entity resolution, es el proceso de determinar que dos o más registros de información, que referencian a un objeto único en el mundo real, pueden ser una misma entidad. Por ejemplo, Bob Smith, Robert Smith y Robert S. podrían referirse a la misma persona, lo mismo podría suceder con una dirección. Es importante mencionar que la información requerida para este equipo es de identificación personal (PII), la cual está categorizada y protegida con las máximas restricciones dentro de la compañía, lo que justifica la estricta gestión de los registros y la prohibición de usar datos reales en ambientes de desarrollo.

El enfoque actual propone un método alternativo para la generación de datos sintéticos utilizando inteligencia artificial. Estos datos sintéticos son utilizados en pruebas de nuevo software en entornos no productivos en Equifax. Para el equipo de \textbf{Keying and Linking} y la compañía, es importante evaluar los nuevos desarrollos, pero es aún más importante proteger la privacidad y seguridad de los datos. Es por ello que la privacidad y calidad de estos datos son relevantes.

En cuanto a la regulación y el acceso directo a la información personal legible y no enmascarada en Equifax, ésta está regulada y solo disponible para proyectos categorizados como Protegidos. Estos proyectos están administrados por un equipo especializado en infraestructura, responsable de la seguridad y las herramientas ofrecidas para dichos espacios de trabajo. Los permisos de acceso son supervisados y revisados periódicamente.

Equifax, como empresa orientada a la IA (\emph{AI-First Company}), está en una constante evolución buscando ser pionera en inteligencia artificial, utilizando los datos almacenados durante más de un siglo y su asociación con Google, su principal proveedor de servicios en la nube. El objetivo para 2022 es tener la capacidad de entrenar modelos de Deep Learning usando las plataformas analíticas actuales administradas por la compañía; el producto seleccionado y en proceso de implementación es Vertex AI. Equifax se encuentra en proceso de evaluación de empresas que generan datos sintéticos acordes a las necesidades de la organización. Una de las evaluadas es Tonic IA \url{https://www.tonic.ai/}, lo que evidencia la relevancia que tienen los datos sintéticos en los objetivos a mediano plazo de Equifax.

\newpage
\section{Objetivo}

\textbf{Objetivo General:}

El objetivo general de este trabajo es establecer un mecanismo para la generación de conjuntos de datos sintéticos estructurados, los cuales incluyen texto, y proceder a compararlos con sus equivalentes originales.

\textbf{Objetivos Específicos:}
\begin{enumerate}
    \item Utilización de modelos generativos capaces de producir nuevos conjuntos de datos sintéticos a partir de datos originales que contienen texto.
    \item Evaluar y comparar las características de los conjuntos de datos sintéticos y originales en tres aspectos: propiedades estadísticas, nivel de privacidad, y sus distribuciones.
\end{enumerate}

\section{Estructura del documento}

\textbf{\fullref{chap:revision}:}  \\
Este capítulo proporciona una revisión bibliográfica que abarca tipos de datos, privacidad de datos y generación de datos sintéticos. Se discuten y resumen los diferentes tipos de datos, se subraya la importancia de la protección de datos, y se discuten los enfoques de generación de datos sintéticos.

\textbf{\fullref{chap:desarrollo}:}  \\
Este capítulo detalla el proceso de desarrollo del estudio, incluyendo: 
\textbf{\nameref{subsec:datos},} Se describen detalladamente las bases de datos utilizadas, con una visión general de sus campos y características. 
\textbf{\nameref{subsec:computacion},} Se proporciona una descripción detallada de los recursos de hardware y software empleados. 
\textbf{\nameref{subsec:procesamiento},} Se ofrece una descripción completa del flujo de procesamiento implementado, basado en la metodología de Synthetic Data Vault (SDV). 
\textbf{\nameref{subsec:generacion},} Se presentan y describen los modelos de generación de datos tabulares y de texto utilizados y finalmente
\textbf{\nameref{subsec:metricas},} Se detalla la metodología empleada para obtener y calcular las métricas para la evaluación de los conjuntos de datos sintéticos.

%\chapter{Resultados}
\textbf{\fullref{chap:resultados}:} \\
Los resultados del estudio se presentan en este capítulo, dividido en dos secciones principales: King County y Económicos. En cada sección, se discuten detalladamente los resultados obtenidos para cada conjunto de datos.

%\chapter{Conclusiones y Discusión}
\textbf{\fullref{chap:conclusion}:} \\
Este capítulo se divide en tres secciones principales: \textbf{\nameref{sec:conclusion},}
Se recapitula el objetivo del estudio y se discuten los hallazgos más significativos.
\textbf{\nameref{sec:limit},}
Se reconocen y discuten las limitaciones del estudio.
Se presenta un ejemplo del uso de ChatGPT para ilustrar la relevancia de la generación de datos sintéticos.
\textbf{\nameref{sec:discusion},}
Se discute sobre los modelos emergentes de generación de texto y la necesidad de futuros estudios en esta área, incluyendo la importancia de evaluar la privacidad.
