
@online{smith-goodson_ibm_nodate,
	title = {{IBM} Demonstrates Groundbreaking Artificial Intelligence Research Using Foundational Models And Generative {AI}},
	url = {https://www.forbes.com/sites/moorinsights/2023/02/13/ibm-demonstrates-groundbreaking-artificial-intelligence-research-using-foundational-models-and-generative-ai/},
	abstract = {Vice President of {AI} \& Quantum Computing, Paul Smith-Goodson, dives in as he sheds light on the life-saving potential of {AI} by examining its practical applications in the creation of new antibiotics and other scientific {AI} tools.},
	titleaddon = {Forbes},
	author = {Smith-Goodson, Paul},
	urldate = {2023-02-19},
	langid = {english},
	note = {Section: Cloud},
	file = {Snapshot:/home/gvillarroel/Zotero/storage/YM8XEWL7/ibm-demonstrates-groundbreaking-artificial-intelligence-research-using-foundational-models-and-.html:text/html},
}

@misc{openai_chatgpt_2023,
	title = {{ChatGPT}: a large language model trained by {OpenAI}},
	url = {https://openai.com/blog/chatgpt-a-large-scale-generative-language-model/},
	author = {{OpenAI}},
	date = {2023},
}

@inproceedings{krizhevsky_imagenet_2012,
	title = {{ImageNet} Classification with Deep Convolutional Neural Networks},
	volume = {25},
	url = {https://proceedings.neurips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html},
	abstract = {We trained a large, deep convolutional neural network to classify the 1.3 million high-resolution images in the {LSVRC}-2010 {ImageNet} training set into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 39.7{\textbackslash}\% and 18.9{\textbackslash}\% which is considerably better than the previous state-of-the-art results. The neural network, which has 60 million parameters and 500,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and two globally connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient {GPU} implementation of convolutional nets. To reduce overfitting in the globally connected layers we employed a new regularization method that proved to be very effective.},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	urldate = {2023-02-19},
	date = {2012},
	file = {Full Text PDF:/home/gvillarroel/Zotero/storage/V3M7SMI6/Krizhevsky et al. - 2012 - ImageNet Classification with Deep Convolutional Ne.pdf:application/pdf},
}

@online{noauthor_papers_nodate,
	title = {Papers with Code - {ImageNet} Benchmark (Image Classification)},
	url = {https://paperswithcode.com/sota/image-classification-on-imagenet},
	abstract = {The current state-of-the-art on {ImageNet} is {CoCa} (finetuned). See a full comparison of 846 papers with code.},
	urldate = {2023-02-19},
	langid = {english},
	file = {Snapshot:/home/gvillarroel/Zotero/storage/78KURA4J/image-classification-on-imagenet.html:text/html},
}

@online{noauthor_dalle_nodate,
	title = {{DALL}·E 2},
	url = {https://openai.com/dall-e-2/},
	abstract = {{DALL}·E 2 is a new {AI} system that can create realistic images and art from a description in natural language.},
	titleaddon = {{OpenAI}},
	urldate = {2023-02-19},
	langid = {english},
	file = {Snapshot:/home/gvillarroel/Zotero/storage/N7ICEGKB/dall-e-2.html:text/html},
}

@online{noauthor_stable_nodate,
	title = {Stable Diffusion Public Release},
	url = {https://stability.ai/blog/stable-diffusion-public-release},
	abstract = {We are delighted to announce the public release of Stable Diffusion and the launch of {DreamStudio} Lite.},
	titleaddon = {Stability {AI}},
	urldate = {2023-02-19},
	langid = {british},
	file = {Snapshot:/home/gvillarroel/Zotero/storage/ZCN9GW22/stable-diffusion-public-release.html:text/html},
}

@online{noauthor_imagen_nodate,
	title = {Imagen: Text-to-Image Diffusion Models},
	url = {https://imagen.research.google/},
	urldate = {2023-02-19},
	file = {Imagen\: Text-to-Image Diffusion Models:/home/gvillarroel/Zotero/storage/P5KGIZW2/imagen.research.google.html:text/html},
}

@online{noauthor_chatgpt-initiated_2023,
	title = {{ChatGPT}-initiated {AI} war},
	url = {https://www.koreatimes.co.kr/www/opinion/2023/02/202_345310.html},
	abstract = {Global tech giants are rushing to take the lead in artificial intelligence ({AI}), prompted by the sweeping frenzy of {ChatGPT}. The U.S.' {OpenAI} first unveiled the Chat Generative Pre-trained Transformer ({ChatGPT}) in December last year. Such state-of-the-art technology generated a stir as the number of its monthly users surpassed 100 million in two months, nudging desperate Microsoft and Google to come up with their own new {AI} services.},
	titleaddon = {koreatimes},
	urldate = {2023-02-19},
	date = {2023-02-13},
	langid = {english},
	note = {Section: Opinion},
}

@online{noauthor_microsoft_2023,
	title = {Microsoft and Google are in a ‘Game of Thrones’ battle over A.I.— but Apple and Amazon still have huge roles to play, according to Wedbush},
	url = {https://finance.yahoo.com/news/microsoft-google-game-thrones-battle-174112314.html},
	abstract = {Tech companies are racing to figure out how to implement A.I. in their products, and it’s not just about search engines.},
	urldate = {2023-02-19},
	date = {2023-02-15},
	langid = {american},
}

@article{milmo_google_2023,
	title = {Google v Microsoft: who will win the {AI} chatbot race?},
	issn = {0261-3077},
	url = {https://www.theguardian.com/technology/2023/feb/10/google-v-microsoft-who-will-win-the-ai-chatbot-race-bard-chatgpt},
	shorttitle = {Google v Microsoft},
	abstract = {Bard’s misfire on launch cost owner \$160bn but experts believe {ChatGPT} is also prone to errors},
	journaltitle = {The Guardian},
	author = {Milmo, Dan and editor, Dan Milmo Global technology},
	urldate = {2023-02-19},
	date = {2023-02-10},
	langid = {british},
	keywords = {Alphabet, Artificial intelligence ({AI}), Business, {ChatGPT}, Computing, Google, Microsoft, Technology, Technology sector, {US} news, World news},
	file = {Snapshot:/home/gvillarroel/Zotero/storage/93EMKRV8/google-v-microsoft-who-will-win-the-ai-chatbot-race-bard-chatgpt.html:text/html},
}

@online{noauthor_exclusive_2023,
	title = {Exclusive: The \$2 Per Hour Workers Who Made {ChatGPT} Safer},
	url = {https://time.com/6247678/openai-chatgpt-kenya-workers/},
	shorttitle = {Exclusive},
	abstract = {A {TIME} investigation reveals the difficult conditions faced by the workers who made {ChatGPT} possible},
	titleaddon = {Time},
	urldate = {2023-02-19},
	date = {2023-01-18},
	langid = {english},
	file = {Snapshot:/home/gvillarroel/Zotero/storage/7HRC8MFD/openai-chatgpt-kenya-workers.html:text/html},
}

@book{el_emam_practical_2020,
	title = {Practical synthetic data generation: balancing privacy and the broad availability of data},
	publisher = {O'Reilly Media},
	author = {El Emam, Khaled and Mosquera, Lucy and Hoptroff, Richard},
	date = {2020},
}

@article{vaswani_attention_2017,
	title = {Attention is all you need},
	volume = {30},
	journaltitle = {Advances in neural information processing systems},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \{{\textbackslash}textbackslash\}Lukasz and Polosukhin, Illia},
	date = {2017},
}

@book{bruce_practical_2020,
	title = {Practical statistics for data scientists: 50+ essential concepts using R and Python},
	publisher = {O'Reilly Media},
	author = {Bruce, Peter and Bruce, Andrew and Gedeck, Peter},
	date = {2020},
}

@article{gantz_digital_2012,
	title = {The digital universe in 2020: Big data, bigger digital shadows, and biggest growth in the far east},
	volume = {2007},
	url = {https://datastorageasean.com/sites/default/files/idc-the-digital-universe-in-2020.pdf},
	pages = {1--16},
	number = {2012},
	journaltitle = {{IDC} {iView}: {IDC} Analyze the future},
	author = {Gantz, John and Reinsel, David},
	date = {2012},
}

@article{adnan_analytical_2019,
	title = {An analytical study of information extraction from unstructured and multidimensional big data},
	volume = {6},
	url = {https://link.springer.com/article/10.1186/s40537-019-0254-8},
	pages = {1--38},
	journaltitle = {Journal of Big Data},
	author = {Adnan, Kiran and Akbar, Rehan},
	date = {2019},
	note = {Publisher: Springer},
}

@article{de_capitani_di_vimercati_data_2012,
	title = {Data privacy: Definitions and techniques},
	volume = {20},
	pages = {793--817},
	number = {6},
	journaltitle = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
	author = {De Capitani Di Vimercati, Sabrina and Foresti, Sara and Livraga, Giovanni and Samarati, Pierangela},
	date = {2012},
	note = {Publisher: World Scientific},
}

@article{regulation_regulation_2016,
	title = {Regulation ({EU}) 2016/679 of the European Parliament and of the Council},
	volume = {679},
	url = {https://dvbi.ru/Portals/0/DOCUMENTS_SHARE/RISK_MANAGEMENT/EBA/GDPR_eng_rus.pdf},
	pages = {2016},
	journaltitle = {Regulation (eu)},
	author = {Regulation, Protection},
	date = {2016},
}

@article{pardau_california_2018,
	title = {The California consumer privacy act: Towards a European-style privacy regime in the United States},
	volume = {23},
	pages = {68},
	journaltitle = {J. Tech. L. \& Pol'y},
	author = {Pardau, Stuart L},
	date = {2018},
	note = {Publisher: {HeinOnline}},
}

@article{act_health_1996,
	title = {Health insurance portability and accountability act of 1996},
	volume = {104},
	url = {http://www.eolusinc.com/pdf/hipaa.pdf},
	pages = {191},
	journaltitle = {Public law},
	author = {Act, Accountability},
	date = {1996},
}

@article{rosenblatt_differentially_2020,
	title = {Differentially private synthetic data: Applied evaluations and enhancements},
	url = {https://arxiv.org/abs/2011.05537},
	journaltitle = {{arXiv} preprint {arXiv}:2011.05537},
	author = {Rosenblatt, Lucas and Liu, Xiaoyan and Pouyanfar, Samira and de Leon, Eduardo and Desai, Anuj and Allen, Joshua},
	date = {2020},
}

@inproceedings{dwork_differential_2006,
	title = {Differential privacy},
	pages = {1--12},
	booktitle = {Automata, Languages and Programming: 33rd International Colloquium, {ICALP} 2006, Venice, Italy, July 10-14, 2006, Proceedings, Part {II} 33},
	publisher = {Springer},
	author = {Dwork, Cynthia},
	date = {2006},
}

@inproceedings{dwork_calibrating_2006,
	title = {Calibrating noise to sensitivity in private data analysis},
	pages = {265--284},
	booktitle = {Theory of Cryptography: Third Theory of Cryptography Conference, {TCC} 2006, New York, {NY}, {USA}, March 4-7, 2006. Proceedings 3},
	publisher = {Springer},
	author = {Dwork, Cynthia and {McSherry}, Frank and Nissim, Kobbi and Smith, Adam},
	date = {2006},
}

@article{solatorio_realtabformer_2023,
	title = {{REaLTabFormer}: Generating Realistic Relational and Tabular Data using Transformers},
	journaltitle = {{arXiv} preprint {arXiv}:2302.02041},
	author = {Solatorio, Aivin V and Dupriez, Olivier},
	date = {2023},
}

@article{rajabi_tabfairgan_2022,
	title = {Tabfairgan: Fair tabular data generation with generative adversarial networks},
	volume = {4},
	pages = {488--501},
	number = {2},
	journaltitle = {Machine Learning and Knowledge Extraction},
	author = {Rajabi, Amirarsalan and Garibay, Ozlem Ozmen},
	date = {2022},
	note = {Publisher: {MDPI}},
}

@article{thambawita_singan-seg_2022,
	title = {{SinGAN}-Seg: Synthetic training data generation for medical image segmentation},
	volume = {17},
	pages = {e0267976},
	number = {5},
	journaltitle = {{PloS} one},
	author = {Thambawita, Vajira and Salehi, Pegah and Sheshkal, Sajad Amouei and Hicks, Steven A and Hammer, Hugo L and Parasa, Sravanthi and Lange, Thomas de and Halvorsen, Pål and Riegler, Michael A},
	date = {2022},
	note = {Publisher: Public Library of Science San Francisco, {CA} {USA}},
}

@article{park_data_2018,
	title = {Data synthesis based on generative adversarial networks},
	journaltitle = {{arXiv} preprint {arXiv}:1806.03384},
	author = {Park, Noseong and Mohammadi, Mahmoud and Gorde, Kshitij and Jajodia, Sushil and Park, Hongkyu and Kim, Youngmin},
	date = {2018},
}

@article{borisov_language_2022,
	title = {Language models are realistic tabular data generators},
	url = {https://arxiv.org/pdf/2210.06280.pdf},
	journaltitle = {{arXiv} preprint {arXiv}:2210.06280},
	author = {Borisov, Vadim and Seßler, Kathrin and Leemann, Tobias and Pawelczyk, Martin and Kasneci, Gjergji},
	date = {2022},
}

@article{pujol_prefair_2022,
	title = {{PreFair}: Privately Generating Justifiably Fair Synthetic Data},
	journaltitle = {{arXiv} preprint {arXiv}:2212.10310},
	author = {Pujol, David and Gilad, Amir and Machanavajjhala, Ashwin},
	date = {2022},
}

@article{acharya_gensyn_2022,
	title = {{GenSyn}: A Multi-stage Framework for Generating Synthetic Microdata using Macro Data Sources},
	journaltitle = {{arXiv} preprint {arXiv}:2212.05975},
	author = {Acharya, Angeela and Sikdar, Siddhartha and Das, Sanmay and Rangwala, Huzefa},
	date = {2022},
}

@inproceedings{zhao_ctab-gan_2021,
	title = {{CTAB}-{GAN}: Effective Table Data Synthesizing},
	volume = {157},
	url = {https://proceedings.mlr.press/v157/zhao21a.html},
	series = {Proceedings of Machine Learning Research},
	abstract = {While data sharing is crucial for knowledge development, privacy concerns and strict regulation (e.g., European General Data Protection Regulation ({GDPR})) unfortunately limit its full effectiveness. Synthetic tabular data emerges as an alternative to enable data sharing while fulfilling regulatory and privacy constraints. The state-of-the-art tabular data synthesizers draw methodologies from Generative Adversarial Networks ({GAN}) and address two main data types in industry, i.e., continuous and categorical. In this paper, we develop {CTAB}-{GAN}, a novel conditional table {GAN} architecture that can effectively model diverse data types, including a mix of continuous and categorical variables. Moreover, we address data imbalance and long tail issues, i.e., certain variables have drastic frequency differences across large values. To achieve those aims, we first introduce the information loss, classification loss and generator loss to the conditional {GAN}. Secondly, we design a novel conditional vector, which efficiently encodes the mixed data type and skewed distribution of data variable. We extensively evaluate {CTAB}-{GAN} with the state of the art {GANs} that generate synthetic tables, in terms of data similarity and analysis utility. The results on five datasets show that the synthetic data of {CTAB}-{GAN} remarkably resembles the real data for all three types of variables and results into higher accuracy for five machine learning algorithms, by up to 17\%.},
	pages = {97--112},
	booktitle = {Proceedings of The 13th Asian Conference on Machine Learning},
	publisher = {{PMLR}},
	author = {Zhao, Zilong and Kunar, Aditya and Birke, Robert and Chen, Lydia Y.},
	editor = {Balasubramanian, Vineeth N. and Tsang, Ivor},
	date = {2021-11-17},
}

@article{zhao_ctab-gan_2022,
	title = {{CTAB}-{GAN}+: Enhancing Tabular Data Synthesis},
	journaltitle = {{arXiv} preprint {arXiv}:2204.00401},
	author = {Zhao, Zilong and Kunar, Aditya and Birke, Robert and Chen, Lydia Y},
	date = {2022},
}

@article{kotelnikov_tabddpm_2022,
	title = {{TabDDPM}: Modelling Tabular Data with Diffusion Models},
	journaltitle = {{arXiv} preprint {arXiv}:2209.15421},
	author = {Kotelnikov, Akim and Baranchuk, Dmitry and Rubachev, Ivan and Babenko, Artem},
	date = {2022},
}

@inproceedings{patki_synthetic_2016,
	title = {The synthetic data vault},
	pages = {399--410},
	booktitle = {2016 {IEEE} International Conference on Data Science and Advanced Analytics ({DSAA})},
	publisher = {{IEEE}},
	author = {Patki, Neha and Wedge, Roy and Veeramachaneni, Kalyan},
	date = {2016},
}

@article{chawla_smote_2002,
	title = {{SMOTE}: synthetic minority over-sampling technique},
	volume = {16},
	pages = {321--357},
	journaltitle = {Journal of artificial intelligence research},
	author = {Chawla, Nitesh V and Bowyer, Kevin W and Hall, Lawrence O and Kegelmeyer, W Philip},
	date = {2002},
}

@article{xu_modeling_2019,
	title = {Modeling tabular data using conditional gan},
	volume = {32},
	journaltitle = {Advances in Neural Information Processing Systems},
	author = {Xu, Lei and Skoularidou, Maria and Cuesta-Infante, Alfredo and Veeramachaneni, Kalyan},
	date = {2019},
}

@article{kale_text--text_2020,
	title = {Text-to-text pre-training for data-to-text tasks},
	journaltitle = {{arXiv} preprint {arXiv}:2005.10433},
	author = {Kale, Mihir and Rastogi, Abhinav},
	date = {2020},
}

@article{devlin_bert_2018,
	title = {Bert: Pre-training of deep bidirectional transformers for language understanding},
	journaltitle = {{arXiv} preprint {arXiv}:1810.04805},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	date = {2018},
}

@article{herzig_tapas_2020,
	title = {{TaPas}: Weakly supervised table parsing via pre-training},
	journaltitle = {{arXiv} preprint {arXiv}:2004.02349},
	author = {Herzig, Jonathan and Nowak, Pawe\{{\textbackslash}textbackslash\}l Krzysztof and Müller, Thomas and Piccinno, Francesco and Eisenschlos, Julian Martin},
	date = {2020},
}

@article{andrejczuk_table--text_2022,
	title = {Table-To-Text generation and pre-training with {TabT}5},
	journaltitle = {{arXiv} preprint {arXiv}:2210.09162},
	author = {Andrejczuk, Ewa and Eisenschlos, Julian Martin and Piccinno, Francesco and Krichene, Syrine and Altun, Yasemin},
	date = {2022},
}
